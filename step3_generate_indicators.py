#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Step3: æŠ€æœ¯æŒ‡æ ‡ç”Ÿæˆå™¨ï¼ˆå®Œå…¨é…ç½®é©±åŠ¨ç‰ˆï¼‰

âœ¨ ç‰¹æ€§ï¼š
  - å®Œå…¨ç”± main_config.yaml + base_indicators.yaml é©±åŠ¨
  - è‡ªåŠ¨å¤„ç† fixed/sliding æ¨¡å¼
  - æ”¯æŒæŒ‡æ ‡å­é›†é€‰æ‹©æˆ–å…¨é‡è®¡ç®—
  - æ”¯æŒæ—¶é—´èŒƒå›´è¿‡æ»¤

ğŸ“‹ ç”¨æ³•ï¼š
  python step3_generate_indicators.py
  python step3_generate_indicators.py --start 2024-01-01 --end 2024-12-31

ğŸ”§ é…ç½®ï¼š
  - å…¨å±€é…ç½®: main_config.yaml
  - æŒ‡æ ‡å‚æ•°: base_indicators.yaml
"""

from __future__ import annotations

import os
import sys
import argparse
from pathlib import Path

try:
    import pandas as pd
except ImportError:
    print("âŒ å¯¼å…¥ pandas å¤±è´¥ï¼Œè¯·è¿è¡Œ: pip install pandas")
    sys.exit(1)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
_PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
if _PROJECT_ROOT not in sys.path:
    sys.path.insert(0, _PROJECT_ROOT)

try:
    from features_engineering.indicators import IndicatorCalculator
    from features_engineering.congfigs.config_loader import ConfigLoader
except Exception as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)

# ğŸ”¥ åŠ¨æ€è®¾ç½®æŒ‡æ ‡é…ç½®è·¯å¾„ï¼ˆä»å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•æ¨å¯¼ï¼‰
if "INDICATORS_CONFIG" not in os.environ:
    _CONFIG_DIR = os.path.join(os.path.dirname(__file__), "congfigs")
    _INDICATORS_CONFIG = os.path.join(_CONFIG_DIR, "base_indicators.yaml")
    os.environ["INDICATORS_CONFIG"] = os.path.abspath(_INDICATORS_CONFIG)

# å·¥å…·ï¼ˆå¢é‡/è¯»å†™ï¼‰
from features_engineering.tools.io_paths import read_df_auto
from features_engineering.tools.incremental import safe_concat_dedup


def parse_args() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="Step3: æŠ€æœ¯æŒ‡æ ‡ç”Ÿæˆå™¨ï¼ˆå®Œå…¨é…ç½®é©±åŠ¨ï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # ä½¿ç”¨é»˜è®¤é…ç½®
  python step3_generate_indicators.py

  # æŒ‡å®šæ—¶é—´èŒƒå›´
  python step3_generate_indicators.py --start 2024-01-01 --end 2024-12-31

  # è¦†ç›–è¾“å‡ºæ ¼å¼
  python step3_generate_indicators.py --output_format parquet
        """,
    )
    parser.add_argument("--start", type=str, default=None, help="èµ·å§‹æ—¶é—´(å¯é€‰)ï¼Œå¦‚ 2024-01-01")
    parser.add_argument("--end", type=str, default=None, help="ç»“æŸæ—¶é—´(å¯é€‰)ï¼Œå¦‚ 2024-12-31")
    parser.add_argument(
        "--output_format",
        type=str,
        default=None,
        choices=["csv", "parquet", "both"],
        help="è¦†ç›–è¾“å‡ºæ ¼å¼ï¼ˆé»˜è®¤ä» main_config.yaml è¯»å–ï¼‰",
    )
    return parser.parse_args()


def read_kline(
    kline_dir: str,
    symbol: str,
    tf: str,
    start: str | None,
    end: str | None,
    rolling: bool = False,
    preferred_fmt: str | None = None,
) -> pd.DataFrame:
    """è¯»å–æŒ‡å®šå‘¨æœŸçš„Kçº¿æ•°æ®ï¼ˆæ ¹ç›®å½•ç»“æ„ï¼škline/{symbol}_{tf}.parquetï¼Œä¸ Step2 å¯¹é½ï¼‰ã€‚"""
    fname_new = f"{symbol}_{tf}"

    # ğŸ”¥ æ ¹ç›®å½•ç»“æ„ï¼ˆä¸ Step2 ä¿å­˜è·¯å¾„å¯¹é½ï¼‰
    csv_path = Path(kline_dir) / f"{fname_new}.csv"
    parquet_path = Path(kline_dir) / f"{fname_new}.parquet"

    # ä¾æ®é¦–é€‰æ ¼å¼è¯»å–ï¼Œä¸å­˜åœ¨åˆ™è‡ªåŠ¨å›é€€
    fmt = (preferred_fmt or "parquet").lower()
    fmt = "parquet" if fmt not in ("csv", "parquet", "both") else fmt
    paths_try: list[tuple[str, Path]]
    if fmt == "parquet":
        paths_try = [("parquet", parquet_path), ("csv", csv_path)]
    elif fmt == "csv":
        paths_try = [("csv", csv_path), ("parquet", parquet_path)]
    else:  # both
        paths_try = [("parquet", parquet_path), ("csv", csv_path)]

    df = None
    used = None
    for kind, path in paths_try:
        if path.exists():
            used = kind
            if kind == "csv":
                df = pd.read_csv(path)
            else:
                df = pd.read_parquet(path)
            break

    if df is None:
        # å…¼å®¹æ—§è·¯å¾„ï¼šå­ç›®å½•ç»“æ„ï¼ˆå‘åå…¼å®¹ï¼‰
        csv_old_subdir = Path(kline_dir) / tf / f"{fname_new}.csv"
        parquet_old_subdir = Path(kline_dir) / tf / f"{fname_new}.parquet"
        if parquet_old_subdir.exists():
            df = pd.read_parquet(parquet_old_subdir)
        elif csv_old_subdir.exists():
            df = pd.read_csv(csv_old_subdir)
        else:
            raise FileNotFoundError(f"æœªæ‰¾åˆ°Kçº¿æ–‡ä»¶: {parquet_path} æˆ– {csv_path}")

    # è§£ææ—¶é—´ç´¢å¼•ï¼ˆæ™ºèƒ½æ£€æµ‹ï¼šæ•´æ•°ç”¨æ¯«ç§’ï¼Œå­—ç¬¦ä¸²è‡ªåŠ¨æ¨æ–­ï¼‰
    if "timestamp" in df.columns:
        if pd.api.types.is_integer_dtype(df["timestamp"]):
            df["timestamp"] = pd.to_datetime(df["timestamp"], unit="ms", errors="coerce")
        else:
            df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce")
        df = df.set_index("timestamp")
    elif not isinstance(df.index, pd.DatetimeIndex):
        first_col = df.iloc[:, 0]
        if pd.api.types.is_integer_dtype(first_col):
            df.iloc[:, 0] = pd.to_datetime(first_col, unit="ms", errors="coerce")
        else:
            df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0], errors="coerce")
        df = df.set_index(df.columns[0])

    df.index.name = "timestamp"

    # åªä¿ç•™æ ‡å‡†OHLCV
    keep_cols = [c for c in ["open", "high", "low", "close", "volume"] if c in df.columns]
    df = df[keep_cols]

    # æ’åº/å»é‡
    df = df[~df.index.duplicated(keep="last")].sort_index()

    # æ—¶é—´åˆ‡ç‰‡
    if start:
        df = df[df.index >= pd.to_datetime(start)]
    if end:
        df = df[df.index <= pd.to_datetime(end)]

    if df.empty:
        raise ValueError("ç­›é€‰åçš„Kçº¿ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ—¶é—´èŒƒå›´")

    return df


def save_output(df: pd.DataFrame, ind_dir: str, symbol: str, tf: str, fmt: str):
    """ä¿å­˜æŒ‡æ ‡æ•°æ®ï¼ˆæ ¹ç›®å½•ï¼Œä¸åˆ›å»ºæŒ‰å‘¨æœŸå­ç›®å½•ï¼›æ–‡ä»¶å {symbol}_{tf}_indicatorsï¼‰"""
    output_dir = Path(ind_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    fname = f"{symbol}_{tf}_indicators"

    if fmt in ("csv", "both"):
        csv_path = output_dir / f"{fname}.csv"
        df.reset_index().to_csv(csv_path, index=False)
        print(f"   âœ“ CSV: {csv_path.name}")

    if fmt in ("parquet", "both"):
        parquet_path = output_dir / f"{fname}.parquet"
        try:
            df.to_parquet(parquet_path, index=True)
            print(f"   âœ“ Parquet: {parquet_path.name}")
        except Exception as e:
            print(f"   âš ï¸ Parquet å†™å…¥å¤±è´¥: {e}")


def execute_step3(
    cfg: dict,
    start: str | None = None,
    end: str | None = None,
    output_format: str | None = None,
    *,
    verbose: bool = True,
) -> dict:
    """æ‰§è¡Œ Step3 æŒ‡æ ‡ç”Ÿæˆé€»è¾‘ï¼Œä¾›è„šæœ¬ä¸ç»Ÿä¸€æµæ°´çº¿å¤ç”¨ã€‚"""
    if not cfg:
        raise ValueError("é…ç½®ä¸èƒ½ä¸ºç©º")

    log = print if verbose else (lambda *args, **kwargs: None)

    log("ğŸš€ Step3 æŒ‡æ ‡ç”Ÿæˆå¯åŠ¨ï¼ˆå®Œå…¨é…ç½®é©±åŠ¨ï¼‰\n")

    symbol = cfg.get("symbol", {}).get("trading_pair_std", "ETH_USDT")

    timeframes_cfg = cfg.get("timeframes", {})
    timeframes = timeframes_cfg.get("resample_targets", ["3m", "15m", "30m", "2h"])
    include_rolling = timeframes_cfg.get("include_rolling", False)
    variant = str(timeframes_cfg.get("variant", "")).strip().lower()
    source_mode = cfg.get("rl_build", {}).get("source_mode", "fixed")

    io_cfg = cfg.get("io", {})
    base_dir = io_cfg.get("base_dir") or os.path.join(os.path.expanduser("~"), "FinRL_bn", "data")
    kline_dir = io_cfg.get("kline_dir") or f"{base_dir}/rl_live/kline"
    ind_dir = io_cfg.get("indicators_dir") or f"{base_dir}/rl_live/ind"

    output_fmt = output_format or io_cfg.get("output_format", "csv")
    io_overwrite = bool(io_cfg.get("overwrite", False))

    params_cfg = cfg.get("params", {})
    default_params = params_cfg.get("default", {})

    log("ğŸ“‹ é…ç½®æ‘˜è¦:")
    log(f"   äº¤æ˜“å¯¹: {symbol}")
    log(f"   ç›®æ ‡å‘¨æœŸ: {', '.join(timeframes)}")
    log(f"   æ•°æ®æ¨¡å¼: {source_mode.upper()} ({'æ»‘çª—æ»šåŠ¨' if source_mode == 'sliding' else 'å›ºå®šKçº¿'})")
    log(f"   è¾“å‡ºæ ¼å¼: {output_fmt.upper()}")
    if variant in ("fixed", "roll"):
        log(f"   è¾“å‡ºå˜ä½“: {variant.upper()}")
    log(f"\nğŸ“‚ è·¯å¾„é…ç½®:")
    log(f"   Kçº¿ç›®å½•: {kline_dir}")
    log(f"   æŒ‡æ ‡ç›®å½•: {ind_dir}")
    if start or end:
        log(f"\nâ° æ—¶é—´èŒƒå›´: {start or '-âˆ'} ~ {end or '+âˆ'}")

    calc = IndicatorCalculator(verbose=verbose)

    log("\n" + "=" * 80)
    log("ğŸ”„ å¼€å§‹è®¡ç®—æŒ‡æ ‡")
    log("=" * 80)

    for tf in timeframes:
        log(f"\nğŸ“ å‘¨æœŸ: {tf}")

        try:
            kline_fixed = read_kline(
                kline_dir, symbol, tf, start, end, rolling=False, preferred_fmt=output_fmt
            )
            log(
                f"   âœ“ Kçº¿[fixed]: {len(kline_fixed):,} è¡Œ ({kline_fixed.index.min()} ~ {kline_fixed.index.max()})"
            )

            params = default_params

            ind_fixed = calc.calculate_all_indicators(kline_fixed, params=params)
            if ind_fixed is None or ind_fixed.empty:
                raise RuntimeError(f"æŒ‡æ ‡è®¡ç®—å¤±è´¥ (å‘¨æœŸ: {tf})")

            log(f"   âœ“ æŒ‡æ ‡[fixed]: {ind_fixed.shape[1]} åˆ—")

            ind_roll_data = None
            if variant in ("fixed", "roll"):
                produce_roll = variant == "roll"
            else:
                produce_roll = include_rolling
            if produce_roll:
                try:
                    kline_roll = read_kline(
                        kline_dir, symbol, tf, start, end, rolling=True, preferred_fmt=output_fmt
                    )
                    log(f"   âœ“ Kçº¿[rolling]: {len(kline_roll):,} è¡Œ")
                    ind_roll = calc.calculate_all_indicators(kline_roll, params=params)
                    if ind_roll is not None and not ind_roll.empty:
                        log(f"   âœ“ æŒ‡æ ‡[rolling]: {ind_roll.shape[1]} åˆ—")
                        ind_roll_data = ind_roll
                except FileNotFoundError:
                    log("   â„¹ï¸  æœªæ‰¾åˆ° rolling Kçº¿ï¼Œè·³è¿‡")
                except Exception as e:
                    log(f"   âš ï¸  rolling å¤„ç†å¤±è´¥: {e}")

            produce_fixed = not produce_roll
            if produce_fixed and not io_overwrite:
                try:
                    for ext in (".parquet", ".csv"):
                        p = Path(ind_dir) / f"{symbol}_{tf}_indicators{ext}"
                        if p.exists():
                            old = read_df_auto(str(p))
                            if "timestamp" in old.columns:
                                if pd.api.types.is_integer_dtype(old["timestamp"]):
                                    old["timestamp"] = pd.to_datetime(
                                        old["timestamp"], unit="ms", errors="coerce"
                                    )
                                else:
                                    old["timestamp"] = pd.to_datetime(old["timestamp"], errors="coerce")
                                old = old.set_index("timestamp")
                            old.index.name = "timestamp"
                            ind_fixed = safe_concat_dedup(old, ind_fixed)
                            log(f"   ğŸ” åˆå¹¶å†å²: {len(ind_fixed):,} è¡Œ")
                            break
                    else:
                        for ext in (".parquet", ".csv"):
                            p = Path(ind_dir) / tf / f"{symbol}_{tf}_indicators{ext}"
                            if p.exists():
                                old = read_df_auto(str(p))
                                if "timestamp" in old.columns:
                                    if pd.api.types.is_integer_dtype(old["timestamp"]):
                                        old["timestamp"] = pd.to_datetime(
                                            old["timestamp"], unit="ms", errors="coerce"
                                        )
                                    else:
                                        old["timestamp"] = pd.to_datetime(old["timestamp"], errors="coerce")
                                    old = old.set_index("timestamp")
                                old.index.name = "timestamp"
                                ind_fixed = safe_concat_dedup(old, ind_fixed)
                                log(f"   ğŸ” åˆå¹¶å†å²: {len(ind_fixed):,} è¡Œ")
                                break
                except Exception as _e:
                    log(f"   âš ï¸ åˆå¹¶å†å²å¤±è´¥: {_e}")

            if produce_fixed:
                save_output(ind_fixed, ind_dir, symbol, tf, output_fmt)

            if ind_roll_data is not None:
                if not io_overwrite:
                    try:
                        for ext in (".parquet", ".csv"):
                            p = Path(ind_dir) / f"{symbol}_{tf}_indicators{ext}"
                            if p.exists():
                                oldr = read_df_auto(str(p))
                                if "timestamp" in oldr.columns:
                                    oldr["timestamp"] = pd.to_datetime(oldr["timestamp"], errors="coerce")
                                    oldr = oldr.set_index("timestamp")
                                oldr.index.name = "timestamp"
                                ind_roll_data = safe_concat_dedup(oldr, ind_roll_data)
                                log(f"   ğŸ” åˆå¹¶å†å²: {len(ind_roll_data):,} è¡Œ")
                                break
                        else:
                            for ext in (".parquet", ".csv"):
                                p = Path(ind_dir) / tf / f"{symbol}_{tf}_indicators{ext}"
                                if p.exists():
                                    oldr = read_df_auto(str(p))
                                    if "timestamp" in oldr.columns:
                                        oldr["timestamp"] = pd.to_datetime(oldr["timestamp"], errors="coerce")
                                        oldr = oldr.set_index("timestamp")
                                    oldr.index.name = "timestamp"
                                    ind_roll_data = safe_concat_dedup(oldr, ind_roll_data)
                                    log(f"   ğŸ” åˆå¹¶å†å²: {len(ind_roll_data):,} è¡Œ")
                                    break
                    except Exception as _e:
                        log(f"   âš ï¸ åˆå¹¶å†å²å¤±è´¥: {_e}")
                save_output(ind_roll_data, ind_dir, symbol, tf, output_fmt)

            log(f"   âœ… å‘¨æœŸ {tf} å®Œæˆ")

        except Exception as e:
            import traceback

            traceback.print_exc()
            raise RuntimeError(f"Step3 å‘¨æœŸ {tf} å¤„ç†å¤±è´¥: {e}") from e

    log("\n" + "=" * 80)
    log("âœ… Step3 æŒ‡æ ‡ç”Ÿæˆå®Œæˆï¼")
    log("=" * 80)
    log(f"\nğŸ“‚ è¾“å‡ºç›®å½•: {ind_dir}")
    log(f"â±ï¸  å¤„ç†å‘¨æœŸ: {', '.join(timeframes)}")
    log(f"ğŸ”§ æ•°æ®æ¨¡å¼: {source_mode.upper()}")

    from features_engineering.tools.io_paths import print_latest_timestamp

    for tf in timeframes:
        kline_path = Path(kline_dir) / f"{symbol}_{tf}.parquet"
        if not kline_path.exists():
            kline_path = Path(kline_dir) / f"{symbol}_{tf}.csv"
        if kline_path.exists():
            print_latest_timestamp(str(kline_path), fast=True)
            break

    log(f"\nğŸ’¡ ä¸‹ä¸€æ­¥æ“ä½œ:")
    log(f"   è¿è¡Œ Step4 èåˆç‰¹å¾:")
    log(f"   python step4_merge_features.py")

    return {
        "symbol": symbol,
        "timeframes": timeframes,
        "kline_dir": kline_dir,
        "indicators_dir": ind_dir,
        "source_mode": source_mode,
        "include_rolling": include_rolling,
        "variant": variant,
        "output_format": output_fmt,
        "start": start,
        "end": end,
    }


def main():
    """ä¸»æµç¨‹ï¼šå®Œå…¨é…ç½®é©±åŠ¨çš„æŒ‡æ ‡ç”Ÿæˆ"""
    args = parse_args()

    try:
        loader = ConfigLoader()
        cfg = loader.load_step3_config()
        if not cfg:
            print("âŒ æœªæ‰¾åˆ°æˆ–æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶")
            return 1

    except Exception as e:
        print(f"âŒ åŠ è½½é…ç½®å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return 1

    try:
        execute_step3(
            cfg,
            start=args.start,
            end=args.end,
            output_format=args.output_format,
            verbose=True,
        )
        return 0
    except Exception as e:
        print(f"âŒ Step3 æ‰§è¡Œå¤±è´¥: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())
