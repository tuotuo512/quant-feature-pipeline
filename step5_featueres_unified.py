#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Step5 Unified: ç‰¹å¾å·¥ç¨‹å¼•æ“ï¼ˆå•Passæ¶æ„ï¼‰

èŒè´£ï¼š
  1. æ¥æ”¶æ¸…æ´—åçš„DataFrame
  2. æ‰§è¡Œ9å¤§ç‰¹å¾åˆ†ç»„å¤„ç†
  3. è¿”å› observations + states + metadata

ä¸è´Ÿè´£ï¼š
  - æ•°æ®è¯»å–/ä¿å­˜
  - çœŸæ»‘çª—å¤„ç†
  - NPZå¯¼å‡º

ç‰¹å¾åˆ†ç»„ï¼ˆ9å¤§ç±»ï¼‰ï¼š
  1. market_state    (SuperTrend â†’ -1/1)
  2. momentum        (æ»šåŠ¨Z-score + robustå½’ä¸€åŒ–)
  3. band_width      (rankå½’ä¸€åŒ–)
  4. volume          (rankå½’ä¸€åŒ–)
  5. ATR/RV          (æ³¢åŠ¨ç‡)
  6. RSI             (è¿ç»­å€¼ + äº‹ä»¶æ ‡è®°)
  7. time_encoding   (sin/coså‘¨æœŸç¼–ç )
  8. price_base      (OHLCåŸºå‡†ä»·æ ¼)
  9. return          (å¯¹æ•°æ”¶ç›Šç‡)
"""

from __future__ import annotations

import re
from typing import Dict, List, Tuple, Any, Optional

import numpy as np
import pandas as pd


# ============================================
# è¾…åŠ©å‡½æ•°
# ============================================


def _period_to_minutes(p: str) -> int:
    """è½¬æ¢å‘¨æœŸå­—ç¬¦ä¸²ä¸ºåˆ†é’Ÿæ•°"""
    val = int(re.findall(r"\d+", p)[0])
    unit = p[-1]
    if unit == "m":
        return val
    elif unit == "h":
        return val * 60
    elif unit == "d":
        return val * 1440
    return val


def _get_period_multipliers(base_period: str, all_periods: List[str]) -> Dict[str, float]:
    """æ ¹æ®åŸºå‡†å‘¨æœŸåŠ¨æ€è®¡ç®—å„å‘¨æœŸç›¸å¯¹å€æ•°"""
    base_minutes = _period_to_minutes(base_period)
    multipliers = {}
    for period in all_periods:
        period_minutes = _period_to_minutes(period)
        multipliers[period] = period_minutes / base_minutes
    return multipliers


def _auto_detect_periods(df: pd.DataFrame) -> List[str]:
    """ä»DataFrameåˆ—åä¸­è‡ªåŠ¨è¯†åˆ«å‘¨æœŸå‰ç¼€"""
    period_pattern = re.compile(r"^(\d+[mhd])_")
    detected = set()
    for col in df.columns:
        match = period_pattern.match(str(col))
        if match:
            detected.add(match.group(1))
    return sorted(detected, key=_period_to_minutes)


def _detect_rsi_column(df: pd.DataFrame, period: str) -> Optional[str]:
    """æŸ¥æ‰¾ç»™å®šå‘¨æœŸçš„ RSI åˆ—åï¼Œå…¼å®¹ rsi ä¸ rsi14 ç­‰å¤šç§å‘½åã€‚"""
    exact = f"{period}_rsi"
    if exact in df.columns:
        return exact
    pattern = re.compile(rf"^{re.escape(period)}_rsi\d+$")
    for col in df.columns:
        if isinstance(col, str) and pattern.match(col):
            return col
    return None


# ============================================
# NumbaåŠ é€Ÿï¼ˆå¯é€‰ï¼‰
# ============================================

_numba_available = False
try:
    from numba import njit  # type: ignore

    _numba_available = True
except Exception:
    pass


if _numba_available:

    @njit(cache=True, fastmath=True)
    def _calc_percentile_rank_nb(series: np.ndarray, window: int) -> np.ndarray:
        """numbaåŠ é€Ÿçš„æ»šåŠ¨ç§©åˆ†ä½è®¡ç®—"""
        n = series.shape[0]
        out = np.empty(n, dtype=np.float64)
        for i in range(n):
            start = max(0, i - window + 1)
            x = series[i]
            less = 0
            equal = 0
            count = 0
            for j in range(start, i + 1):
                v = series[j]
                if v < x:
                    less += 1
                elif v == x:
                    equal += 1
                count += 1
            rank = (less + 0.5 * equal) / max(1, count)
            if rank < 0.01:
                rank = 0.01
            elif rank > 0.99:
                rank = 0.99
            out[i] = rank
        return out


def calc_percentile_rank(series: np.ndarray, window: int) -> np.ndarray:
    """è®¡ç®—æ»šåŠ¨å¹³å‡ç§©åˆ†ä½ï¼ˆèŒƒå›´çº¦[0.01, 0.99]ï¼‰"""
    x = np.asarray(series, dtype=np.float64)
    if window <= 1 or x.size == 0:
        return np.full_like(x, 0.5, dtype=float)
    if _numba_available:
        try:
            return _calc_percentile_rank_nb(x, int(window)).astype(float)
        except Exception:
            pass
    # çº¯Pythonåå¤‡å®ç°
    out = np.zeros_like(x, dtype=float)
    for i in range(len(x)):
        start = max(0, i - window + 1)
        window_vals = x[start : i + 1]
        if window_vals.size == 0:
            out[i] = 0.5
            continue
        xv = x[i]
        less = np.sum(window_vals < xv)
        equal = np.sum(window_vals == xv)
        rank = (less + 0.5 * equal) / window_vals.size
        rank = np.clip(rank, 0.01, 0.99)
        out[i] = rank
    return out


def calc_rolling_zscore(series: np.ndarray, window: int) -> np.ndarray:
    """
    æ»šåŠ¨Z-scoreæ ‡å‡†åŒ–ï¼ˆå‘é‡åŒ–ç‰ˆæœ¬ï¼ŒO(N)å¤æ‚åº¦ï¼‰

    ğŸ”¥ å…³é”®ä¿®å¤: å¤„ç†NaNå€¼ï¼Œé¿å…cumsumä¼ æ’­å¯¼è‡´å…¨å±€æ±¡æŸ“
    """
    v = np.asarray(series, dtype=np.float64)
    n = v.size
    if n == 0:
        return v

    # è®°å½•åŸå§‹NaNä½ç½®
    nan_mask = ~np.isfinite(v)

    # ç”¨0å¡«å……NaNç”¨äºcumsumï¼ˆé¿å…NaNä¼ æ’­ï¼‰
    v_filled = np.where(np.isfinite(v), v, 0.0)

    w = max(1, int(window))
    idx = np.arange(n)
    starts = np.maximum(0, idx - w + 1)
    prev = starts - 1

    csum = np.cumsum(v_filled)
    csum2 = np.cumsum(v_filled * v_filled)

    sum_win = csum - np.where(prev >= 0, csum[prev], 0.0)
    sum2_win = csum2 - np.where(prev >= 0, csum2[prev], 0.0)
    lengths = (idx - starts + 1).astype(np.float64)
    mean = sum_win / np.maximum(1.0, lengths)
    var = sum2_win / np.maximum(1.0, lengths) - mean * mean
    var = np.where(var < 1e-12, 1e-12, var)
    std = np.sqrt(var)

    z = (v_filled - mean) / std

    # è¿˜åŸåŸå§‹NaNä½ç½®
    z[nan_mask] = np.nan
    z[~np.isfinite(z)] = np.nan

    return z.astype(float)


def _calibrate_one_sided_power(
    x: np.ndarray, p: float = 0.95, target: float = 0.99, epsilon: float = 0.0
) -> np.ndarray:
    """å•è¾¹å¹‚å˜æ¢æ ¡å‡†åˆ°[0,1]ï¼š
    - ä»¤ q = quantile(x, p) (0<q<1)ï¼Œæ±‚ Î³ ä½¿ q^Î³ = target â‡’ Î³ = ln(target)/ln(q)
    - y = clip(x,0,1)^Î³ï¼Œå†çº¿æ€§å¤¹ç´§åˆ°[Îµ, 1-Îµ]
    ä¿æŒå•è°ƒä¸”é¿å…å¤§é‡ç‚¹é¥±å’Œåœ¨1ã€‚
    """
    v = np.asarray(x, dtype=float)
    finite_mask = np.isfinite(v)
    y = np.zeros_like(v, dtype=float)
    if finite_mask.any():
        q = float(np.quantile(v[finite_mask], p))
        q = float(np.clip(q, 1e-6, 1 - 1e-6))
        # è‹¥qâ‰ˆ1ï¼Œé¿å…é™¤é›¶ï¼šé€€åŒ–ä¸ºÎ³=1
        if abs(1.0 - q) < 1e-6:
            gamma = 1.0
        else:
            gamma = float(np.log(max(target, 1e-6)) / np.log(q))
        y[finite_mask] = np.power(np.clip(v[finite_mask], 0.0, 1.0), gamma)
    y = np.clip(y, 0.0 + max(0.0, float(epsilon)), 1.0 - max(0.0, float(epsilon)))
    return y.astype(float)


def _apply_fixed_power_calibration(x: np.ndarray, gamma: float, epsilon: float = 0.0) -> np.ndarray:
    """ä½¿ç”¨æŒä¹…åŒ–çš„å¹‚ç³»æ•°è¿›è¡Œå•è¾¹å‹ç¼©ï¼Œä¿æŒè®­ç»ƒ/å®ç›˜ä¸€è‡´ã€‚"""
    v = np.asarray(x, dtype=float)
    gamma = float(gamma) if np.isfinite(gamma) else 1.0
    clipped = np.clip(v, 0.0, 1.0)
    y = np.power(clipped, max(1e-6, gamma))
    return np.clip(y, 0.0 + max(0.0, float(epsilon)), 1.0 - max(0.0, float(epsilon)))


def _get_series(df: pd.DataFrame, target_period: str, suffix: str, roll_mode: bool, base_period: str) -> np.ndarray:
    """
    è·å–æŒ‡å®šå‘¨æœŸå’Œåç¼€çš„åºåˆ—æ•°æ®

    ä¼˜å…ˆçº§ï¼š
    - roll_mode=True: {period}_{suffix}_roll â†’ {period}_{suffix}
    - roll_mode=False: {period}_{suffix}_fixed â†’ {period}_{suffix}
    - å…œåº•: {base_period}_{suffix}
    """
    if roll_mode:
        cand = [f"{target_period}_{suffix}_roll", f"{target_period}_{suffix}"]
    else:
        cand = [f"{target_period}_{suffix}_fixed", f"{target_period}_{suffix}"]

    for col in cand:
        if col in df.columns:
            series = pd.to_numeric(df[col], errors="coerce").fillna(0.0).values.astype(float)
            return np.where(~np.isfinite(series), 0.0, series)

    # å…œåº•ï¼šrollæ¨¡å¼ä¸‹å°è¯•åŸºå‡†å‘¨æœŸ
    if roll_mode and target_period != base_period:
        fallback = f"{base_period}_{suffix}"
        if fallback in df.columns:
            series = pd.to_numeric(df[fallback], errors="coerce").fillna(0.0).values.astype(float)
            return np.where(~np.isfinite(series), 0.0, series)

    return np.zeros(len(df), dtype=float)


# ============================================
# ç‰¹å¾ç»„1: Market State
# ============================================


def calc_market_state_label(df: pd.DataFrame, period: str) -> np.ndarray:
    """
    è®¡ç®—å¸‚åœºçŠ¶æ€æ ‡ç­¾ï¼ˆäºŒåˆ†ç±»ï¼š-1/1ï¼‰

    åŸºäºSuperTrendæ–¹å‘ï¼š
    - ä¼˜å…ˆçº§: {period}_supertrend_direction_roll > _fixed > æ— åç¼€
    - direction >= 0 â†’ 1 (æ¶¨åŠ¿)
    - direction < 0  â†’ -1 (è·ŒåŠ¿)
    """
    st_candidates = [
        f"{period}_supertrend_direction_roll",
        f"{period}_supertrend_direction_fixed",
        f"{period}_supertrend_direction",
    ]
    for col in st_candidates:
        if col in df.columns:
            try:
                arr = pd.to_numeric(df[col], errors="coerce").fillna(0.0).values.astype(float)
                return np.where(arr >= 0.0, 1, -1).astype(int)
            except Exception:
                continue

    print(f"âš ï¸ {period}: æœªæ‰¾åˆ°SuperTrend directionåˆ—ï¼Œè¿”å›å…¨1å ä½")
    return np.ones(len(df), dtype=int)


def analyze_state_distribution(states: np.ndarray, period: str) -> None:
    """åˆ†æå¹¶æ‰“å°å¸‚åœºçŠ¶æ€åˆ†å¸ƒ"""
    unique, counts = np.unique(states, return_counts=True)
    total = len(states)

    state_names = {-1: "è·ŒåŠ¿", 0: "éœ‡è¡", 1: "æ¶¨åŠ¿"}

    print(f"\nğŸ“Š {period} å¸‚åœºçŠ¶æ€åˆ†å¸ƒ:")
    for state, count in zip(unique, counts):
        percentage = count / total * 100
        name = state_names.get(state, f"æœªçŸ¥({state})")
        print(f"  {name}: {count:,} æ ·æœ¬ ({percentage:.1f}%)")

    if len(unique) == 2:
        min_ratio = min(counts) / max(counts)
        if min_ratio < 0.1:
            print("  âš ï¸ æåº¦ä¸å¹³è¡¡")
        elif min_ratio < 0.3:
            print("  âš ï¸ ä¸å¤Ÿå¹³è¡¡")
        else:
            print("  âœ… åˆ†å¸ƒå°šå¯")


# ============================================
# ç‰¹å¾ç»„2: Momentum (çœŸæ»‘çª—ç‰ˆæœ¬)
# ============================================


def calc_rolling_window_momentum(
    df: pd.DataFrame,
    period: str,
    window_minutes: int,
    mom_lookback: int,
    ref_method: str = "boundary",
    anchor_offset: int = 0,
) -> np.ndarray:
    """
    çœŸæ»‘çª—è®¡ç®—momentumï¼ˆæ— æœªæ¥ä¿¡æ¯æ³„éœ²ï¼‰

    å®šä¹‰ï¼ˆä»¥30mä¸ºä¾‹ï¼ŒL=14ï¼‰:
    - pointæ³•ï¼ˆé»˜è®¤ï¼‰: mom_t = close[t] / close[t - L*30m] - 1
    - boundaryæ³•ï¼ˆå¯¹é½åˆ°30mè¾¹ç•Œï¼Œä½†ä¸çœ‹æœªæ¥ï¼‰:
        cur_idx = floor(t/30m)*30m
        mom_t = close[cur_idx] / close[cur_idx - L*30m] - 1
    - boundary_intra_avgï¼ˆå¯¹é½è¾¹ç•Œ+åŒºé—´å‡å€¼å¡«å……ï¼‰:
        åˆ†å­: å½“å‰30måŒºé—´å†…çš„â€œåŸºå‡†æ­¥é•¿â€æ”¶ç›˜å‡å€¼ï¼ˆè¾¹ç•Œèµ·ç‚¹â†’tï¼‰
        åˆ†æ¯: close[t - (L*30m - 30m)]  # ä¾‹ï¼šL=14 â†’ 390åˆ†é’Ÿ

    Args:
        df: åŒ…å«è‡³å°‘ä¸€ä¸ª "<å‘¨æœŸ>_close" åˆ—çš„DataFrameï¼ˆç´¢å¼•æ˜¯æ—¶é—´æˆ³ï¼‰
        period: å‘¨æœŸå­—ç¬¦ä¸² (å¦‚ '30m', '2h')
        window_minutes: å‘¨æœŸå¯¹åº”çš„åˆ†é’Ÿæ•°ï¼ˆ30m->30, 2h->120ï¼‰
        mom_lookback: momentumå›æº¯çª—å£ï¼ˆé»˜è®¤14ï¼‰
        ref_method: å‚è€ƒæ³•ï¼ˆpoint|boundaryï¼‰

    Returns:
        momentumæ•°ç»„ï¼ˆåŸå§‹ç™¾åˆ†æ¯”æ”¶ç›Šç‡ï¼Œå¦‚0.05è¡¨ç¤º5%ï¼‰
    """
    # é€‰æ‹©å¯ç”¨çš„åŸºå‡†æ”¶ç›˜åºåˆ—ï¼šè‡ªåŠ¨é€‰æ‹©åˆ—ä¸­å­˜åœ¨çš„â€œæœ€å°å‘¨æœŸâ€çš„ *_close
    import re as _re

    base_close_col = None
    base_period_detected = None
    candidates = [str(c) for c in df.columns if _re.match(r"^\d+[mhd]_close$", str(c))]
    if candidates:

        def _mins(name: str) -> int:
            return _period_to_minutes(name.split("_")[0])

        candidates.sort(key=_mins)
        base_close_col = candidates[0]
        base_period_detected = base_close_col.split("_")[0]
    if base_close_col is None:
        return np.zeros(len(df), dtype=float)

    close_series = pd.to_numeric(df[base_close_col], errors="coerce").ffill().fillna(0.0).values
    n = len(close_series)

    # ä»¥åŸºå‡†æ­¥é•¿(åˆ†é’Ÿ)æ¢ç®—ç›®æ ‡å‘¨æœŸæ­¥æ•°ä¸å›æº¯æ­¥æ•°
    base_step_minutes = _period_to_minutes(base_period_detected)
    target_minutes = max(1, int(window_minutes))
    steps_per_target = max(1, int(round(float(target_minutes) / float(base_step_minutes))))
    lookback_steps = int(mom_lookback) * steps_per_target

    out = np.full(n, np.nan, dtype=float)

    method = str(ref_method or "boundary").lower().strip()
    anchor_steps = int(round(max(0, int(anchor_offset)) / max(1, base_step_minutes))) % max(1, steps_per_target)
    min_start = lookback_steps + anchor_steps

    if method == "boundary":
        for i in range(min_start, n):
            # å¯¹é½åˆ°ç›®æ ‡å‘¨æœŸè¾¹ç•Œï¼ˆæŒ‰æ­¥é•¿ï¼‰ï¼Œæ”¯æŒé”šç‚¹
            cur_idx = ((i - anchor_steps) // steps_per_target) * steps_per_target + anchor_steps
            past_idx = cur_idx - lookback_steps
            if cur_idx < n and past_idx >= 0:
                cur = close_series[cur_idx]
                prev = close_series[past_idx]
                if np.isfinite(cur) and np.isfinite(prev) and prev != 0.0:
                    out[i] = (cur / prev) - 1.0
    elif method == "boundary_intra_avg":
        # éœ€è¦è‡³å°‘ (L*P - P) çš„å‚è€ƒä½ç§»ï¼ˆæ­¥ï¼‰
        ref_shift_minutes = lookback_steps * base_step_minutes - target_minutes
        ref_shift_steps = max(0, int(round(float(ref_shift_minutes) / float(base_step_minutes))))
        min_start2 = max(min_start, ref_shift_steps + anchor_steps)
        # é¢„è®¡ç®—ç´¯è®¡å’Œç”¨äºå¿«é€Ÿå‡å€¼
        cs = np.cumsum(np.nan_to_num(close_series, nan=0.0))
        for i in range(min_start2, n):
            # å½“å‰å‘¨æœŸè¾¹ç•Œèµ·ç‚¹ï¼ˆæ­¥ï¼‰
            start_idx = ((i - anchor_steps) // steps_per_target) * steps_per_target + anchor_steps
            if start_idx > i:
                continue
            # åŒºé—´å‡å€¼ï¼ˆstart_idx..iï¼‰
            total = cs[i] - (cs[start_idx - 1] if start_idx > 0 else 0.0)
            length = float(i - start_idx + 1)
            cur_avg = total / max(1.0, length)
            # å‚è€ƒä»·ï¼št - (L*P - P)ï¼ˆæ­¥ï¼‰
            past_idx = i - ref_shift_steps
            if past_idx >= 0:
                prev = close_series[past_idx]
                if np.isfinite(cur_avg) and np.isfinite(prev) and prev != 0.0:
                    out[i] = (cur_avg / prev) - 1.0
    else:
        for i in range(min_start, n):
            past_idx = i - lookback_steps
            if past_idx >= 0:
                cur = close_series[i]
                prev = close_series[past_idx]
                if np.isfinite(cur) and np.isfinite(prev) and prev != 0.0:
                    out[i] = (cur / prev) - 1.0

    out = pd.Series(out).ffill().fillna(0.0).values.astype(float)
    return out


def calc_momentum_feature(
    df: pd.DataFrame,
    period: str,
    cfg: Dict,
    roll_mode: bool,
    base_period: str,
    period_multipliers: Dict[str, float],
) -> Tuple[np.ndarray, str]:
    """
    è®¡ç®—åŠ¨é‡ç‰¹å¾ï¼ˆçœŸæ»‘çª— + æ»šåŠ¨Z-score + robustå½’ä¸€åŒ–ï¼‰

    ğŸ”¥ å…³é”®æ”¹è¿›: ä¸å†ä¾èµ–merged.parquetä¸­çš„é˜¶è·ƒmomåˆ—
               è€Œæ˜¯åŸºäºæœ€å°å¯ç”¨æ­¥é•¿çš„ close åºåˆ—é‡æ–°æ»šåŠ¨è®¡ç®—ï¼Œä¿è¯ä¿¡å·å¹³ç¨³è¿ç»­

    è¿”å›: (å½’ä¸€åŒ–åçš„æ•°æ®, å®é™…ä½¿ç”¨çš„åˆ—å)
    """
    # è¯»å–é…ç½®
    norm_cfg = cfg.get("normalization", {})
    mcfg = cfg.get("momentum", norm_cfg.get("momentum", {}))

    # Momentumå›æº¯çª—å£ï¼ˆè®¡ç®—å½“å‰ä»·æ ¼ç›¸å¯¹NæœŸå‰çš„æ¶¨è·Œå¹…ï¼‰
    mom_lookback = int(mcfg.get("default_mom_window", 14))

    # Z-scoreçª—å£
    mom_base = int(mcfg.get("zscore_window", 50))
    use_mult_for_z = bool(mcfg.get("use_period_multipliers_for_zscore", False))
    window = int(mom_base * period_multipliers.get(period, 1)) if use_mult_for_z else mom_base

    # å½’ä¸€åŒ–/æ ¡å‡†å‚æ•°
    norm_method = str(mcfg.get("norm_method", "robust_zscore")).lower()
    robust_k = float(mcfg.get("robust_k", 1.4826))
    # åˆ†ä½æ ¡å‡†ï¼ˆç¡®ä¿æç«¯â‰ˆ5%è´´è¿‘1ï¼‰
    calib_cfg = mcfg.get("calibration") or {}
    calib_method = str(calib_cfg.get("method", "quantile_clip")).lower().strip()
    calib_p = float(calib_cfg.get("p", 0.95))
    calib_target = float(calib_cfg.get("target", 0.99))

    # ğŸ”¥ é¦–é€‰ merged æºï¼šå°½é‡è´´åˆ Step3/Step4 çš„ {period}_mom å€¼
    src_mode = str(mcfg.get("source", "merged")).lower().strip()
    out: np.ndarray
    source_used: str
    merged_col: str | None = None
    if src_mode in ("merged", "auto"):
        exact = f"{period}_mom"
        if exact in df.columns:
            merged_col = exact
        else:
            import re as _re

            cands = [c for c in df.columns if _re.match(rf"^{_re.escape(period)}_mom\d+$", str(c))]
            if cands:
                merged_col = str(cands[0])
            else:
                for c in df.columns:
                    if _re.match(rf"^{_re.escape(period)}_.*mom.*$", str(c)):
                        merged_col = str(c)
                        break
    if merged_col is not None:
        try:
            out = pd.to_numeric(df[merged_col], errors="coerce").fillna(0.0).values.astype(float)
            source_used = merged_col
        except Exception:
            out = None  # type: ignore
    else:
        out = None  # type: ignore

    if out is None:
        # å›é€€ï¼šçœŸæ»‘çª—è®¡ç®—
        window_minutes = _period_to_minutes(period)
        ref_method = str(mcfg.get("momentum_ref_method", "boundary")).lower().strip()
        # æ”¯æŒå…¨å±€æ•°å€¼æˆ–æŒ‰å‘¨æœŸè¦†å†™ï¼š
        # boundary_anchor_offset: 0 | { '30m': 0, '2h': 0 }
        anchor_cfg = mcfg.get("boundary_anchor_offset", 0)
        try:
            if isinstance(anchor_cfg, dict):
                anchor_offset = int(anchor_cfg.get(period, 0))
            else:
                anchor_offset = int(anchor_cfg)
        except Exception:
            anchor_offset = 0
        raw_momentum = calc_rolling_window_momentum(
            df, period, window_minutes, mom_lookback, ref_method=ref_method, anchor_offset=anchor_offset
        )
        out = raw_momentum
        source_used = f"{period}_mom_sliding"

    # ğŸ”¥ æ–°ç®—æ³•ï¼šTanhå‹ç¼©ï¼ˆä»¥0è½´ä¸ºä¸­å¿ƒï¼Œä¿ç•™æ­£è´Ÿæ–¹å‘ï¼‰
    finite_mask = np.isfinite(out)
    normalized = np.zeros_like(out, dtype=float)

    if finite_mask.any():
        # å›ºå®šscaleï¼šå…¸å‹åŠ¨é‡Â±5%æ˜ å°„åˆ°tanh(1.5) â‰ˆ Â±0.905
        # Â±10%æ˜ å°„åˆ°tanh(3) â‰ˆ Â±0.995
        scale = 30.0  # è°ƒèŠ‚çµæ•åº¦

        # Tanhå‹ç¼©ï¼šä¿ç•™æ­£è´Ÿæ–¹å‘ï¼Œå‹åˆ¶æç«¯
        normalized[finite_mask] = np.tanh(out[finite_mask] * scale)

    # NaNå¡«å……
    normalized = np.where(np.isfinite(normalized), normalized, 0.0)

    # ç»Ÿè®¡æç«¯å æ¯”ï¼ˆ|x|â‰¥targetï¼‰
    try:
        extreme_ratio = float(np.mean(np.abs(normalized) >= calib_target))
        print(
            f"   â””â”€ å‡å€¼={np.mean(normalized):.4f}, æ ‡å‡†å·®={np.std(normalized):.4f}, èŒƒå›´=[{np.min(normalized):.4f}, {np.max(normalized):.4f}], æç«¯(|x|>={calib_target:.2f})={extreme_ratio*100:.2f}%"
        )
    except Exception:
        print(
            f"   â””â”€ å‡å€¼={np.mean(normalized):.4f}, æ ‡å‡†å·®={np.std(normalized):.4f}, èŒƒå›´=[{np.min(normalized):.4f}, {np.max(normalized):.4f}]"
        )

    return normalized, source_used


# ============================================
# ç‰¹å¾ç»„3: Band Width
# ============================================


def calc_band_width_feature(
    df: pd.DataFrame,
    period: str,
    cfg: Dict,
    roll_mode: bool,
    base_period: str,
    period_multipliers: Dict[str, float],
) -> Tuple[np.ndarray, str]:
    """è®¡ç®—å¸ƒæ—å¸¦å®½åº¦ç‰¹å¾ï¼ˆrankå½’ä¸€åŒ–ï¼‰"""
    bw_cfg = cfg.get("band_width", {})
    fast_base = int(bw_cfg.get("fast_base", 25))
    slow_base = int(bw_cfg.get("slow_base", 100))
    fuse_w_fast = float(bw_cfg.get("fuse_w_fast", 0.6))
    fuse_w_slow = float(bw_cfg.get("fuse_w_slow", 0.4))
    epsilon = float(bw_cfg.get("shrink_epsilon", 0.03))

    fast_window = int(fast_base * period_multipliers.get(period, 1))
    slow_window = int(slow_base * period_multipliers.get(period, 1))

    suffix = "bb_width"
    bandwidth = _get_series(df, period, suffix, roll_mode, base_period)

    if roll_mode and period != base_period and f"{base_period}_{suffix}" in df.columns:
        source_used = f"{base_period}_{suffix} (roll)"
    elif f"{period}_{suffix}" in df.columns:
        source_used = f"{period}_{suffix}"
    else:
        # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨å¸¦å‘¨æœŸå‰ç¼€çš„åˆ—åï¼Œé¿å…é‡å¤çš„"zeros"åˆ—å
        source_used = f"{period}_bb_width"

    bw = np.log1p(np.maximum(bandwidth, 0.0))

    rank_fast = calc_percentile_rank(bw, fast_window)
    rank_slow = calc_percentile_rank(bw, slow_window)
    rank_fused = fuse_w_fast * rank_fast + fuse_w_slow * rank_slow

    out = rank_fused * (1.0 - 2.0 * epsilon) + epsilon

    print(f"âœ… {period}: band_width (fast={fast_window}, slow={slow_window})")

    return out, source_used


# ============================================
# ç‰¹å¾ç»„4: Volume
# ============================================


def _aggregate_volume_from_base(df: pd.DataFrame, target_period: str, base_period: str) -> Tuple[np.ndarray, str]:
    """
    ä½¿ç”¨åŸºç¡€å‘¨æœŸçš„æˆäº¤é‡æ»šåŠ¨èšåˆå‡ºè¾ƒå¤§å‘¨æœŸçš„volume

    é€»è¾‘ï¼š
        target_period = 15mï¼Œbase_period = 3m
        steps = 15 / 3 = 5
        15m_volume[t] = sum(æœ€è¿‘5ä¸ª3m_volume)
    """
    base_col = f"{base_period}_volume"
    if base_col not in df.columns:
        print(f"      âš ï¸ æœªæ‰¾åˆ°åŸºç¡€æˆäº¤é‡åˆ— {base_col}ï¼Œæ— æ³•èšåˆ {target_period}_volume")
        return np.zeros(len(df), dtype=float), f"{base_period}_volume_missing"

    base_minutes = _period_to_minutes(base_period)
    target_minutes = _period_to_minutes(target_period)
    steps = max(1, int(round(target_minutes / max(1, base_minutes))))

    base_series = pd.to_numeric(df[base_col], errors="coerce").fillna(0.0)
    aggregated = base_series.rolling(window=steps, min_periods=1).sum().values.astype(float)

    if target_period == base_period:
        column_name = f"{target_period}_volume"
    else:
        column_name = f"{base_period}_volumeâ†’{target_period}"
    return aggregated, column_name


def calc_volume_feature(
    df: pd.DataFrame,
    period: str,
    cfg: Dict,
    roll_mode: bool,
    base_period: str,
    period_multipliers: Dict[str, float],
) -> Tuple[np.ndarray, str]:
    """è®¡ç®—æˆäº¤é‡ç‰¹å¾ï¼ˆrankå½’ä¸€åŒ–ï¼‰"""
    vol_base = int(cfg.get("volume", {}).get("rank_window_base", 100))
    window = int(vol_base * period_multipliers.get(period, 1))

    suffix = "volume"
    vol = _get_series(df, period, suffix, roll_mode, base_period)

    if roll_mode and period != base_period and f"{base_period}_{suffix}" in df.columns:
        source_used = f"{base_period}_{suffix} (roll)"
    elif f"{period}_{suffix}" in df.columns:
        source_used = f"{period}_{suffix}"
    else:
        # ğŸ”¥ ä¿®å¤ï¼šä½¿ç”¨å¸¦å‘¨æœŸå‰ç¼€çš„åˆ—åï¼Œé¿å…é‡å¤çš„"zeros"åˆ—å
        source_used = f"{period}_volume"

    # å½“ç›®æ ‡å‘¨æœŸç¼ºå¤±volumeåˆ—æ—¶ï¼Œ_get_seriesä¼šè¿”å›å…¨0æ•°ç»„
    # æ­¤æ—¶ç”¨åŸºç¡€å‘¨æœŸvolumeæ»šåŠ¨èšåˆï¼Œé¿å…å‡ºç°æ’å®šå€¼
    if (np.nanmax(vol) - np.nanmin(vol)) == 0.0:
        vol, source_used = _aggregate_volume_from_base(df, period, base_period)

    vol[np.isnan(vol)] = 0.0
    vol_ln = np.log1p(np.maximum(vol, 0.0))

    out = calc_percentile_rank(vol_ln, window)

    print(f"âœ… {period}: volume (rank_window={window})")

    return out, source_used


# ============================================
# ä¸»ç‰¹å¾å¼•æ“ç±»
# ============================================


class UnifiedFeatureEngine:
    """ç»Ÿä¸€ç‰¹å¾å·¥ç¨‹å¼•æ“ï¼ˆå•Passæ¶æ„ï¼‰"""

    def __init__(self, cfg: Dict, base_period: str = "1m"):
        self.cfg = cfg
        self.base_period = base_period
        self.periods: List[str] = []
        self.period_multipliers: Dict[str, float] = {}
        self.roll_mode: bool = False

        # ğŸ”¥ å½’ä¸€åŒ–é…ç½®ï¼ˆä»cfgä¸­æå–ï¼Œç”¨äºRSIç­‰ç‰¹å¾ï¼‰
        self.norm_config = cfg.get("normalization", {})

        # ç»“æœå®¹å™¨
        self.observations_list: List[np.ndarray] = []
        self.observations_names: List[str] = []
        self.states_list: List[np.ndarray] = []
        self.states_names: List[str] = []
        self.states_types: List[str] = []
        self.num_classes: List[int] = []
        self.timestamps: Optional[np.ndarray] = None
        self.prices: Optional[np.ndarray] = None

    def process(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        å•Passå¤„ç†æµç¨‹

        Args:
            df: è¾“å…¥DataFrameï¼ˆå·²æ¸…æ´—ã€å·²æ»‘çª—ï¼‰

        Returns:
            DictåŒ…å«observations, states, metadataç­‰
        """
        print("\n" + "=" * 70)
        print("ğŸš€ ç‰¹å¾å·¥ç¨‹å¤„ç†")
        print("=" * 70)

        # 1. è‡ªåŠ¨è¯†åˆ«å‘¨æœŸ
        self.periods = _auto_detect_periods(df)
        cfg_periods = self.cfg.get("periods")
        if cfg_periods:
            self.periods = [p for p in self.periods if p in cfg_periods]

        if not self.periods:
            raise RuntimeError("æœªè¯†åˆ«åˆ°ä»»ä½•å‘¨æœŸ")

        print(f"âœ… è¯†åˆ«å‘¨æœŸ: {self.periods}")

        # 2. è®¡ç®—å‘¨æœŸå€æ•°
        self.period_multipliers = _get_period_multipliers(self.base_period, self.periods)
        print(f"âœ… å‘¨æœŸå€æ•°: {self.period_multipliers}")

        # 3. ç¡®å®šrollæ¨¡å¼
        rl_build_cfg = self.cfg.get("rl_build", {})
        source_mode = rl_build_cfg.get("source_mode", "fixed")
        self.roll_mode = source_mode == "sliding"
        print(f"âœ… æ¨¡å¼: {'æ»‘çª—(roll)' if self.roll_mode else 'å›ºå®š(close)'}")

        # 4. æå–æ—¶é—´æˆ³å’Œä»·æ ¼
        self._extract_timestamps_and_prices(df)

        # 5. å¾ªç¯å¤„ç†æ¯ä¸ªå‘¨æœŸ
        for period in self.periods:
            print(f"\nğŸ”„ å¤„ç† {period} å‘¨æœŸ...")
            self._process_period(df, period)

        # 6. å¤„ç†RSI
        self._process_rsi_features(df)

        # 7. å¤„ç†æ—¶é—´ç¼–ç 
        self._process_time_encoding()

        # 8. å¤„ç†åŸºå‡†ä»·æ ¼
        self._process_base_prices(df)

        # 9. å¤„ç†æ”¶ç›Šç‡
        self._process_returns(df)

        # 10. ç»„è£…ç»“æœ
        return self._assemble_results()

    def _extract_timestamps_and_prices(self, df: pd.DataFrame) -> None:
        """æå–æ—¶é—´æˆ³å’Œä»·æ ¼"""
        if isinstance(df.index, pd.DatetimeIndex):
            self.timestamps = df.index.values
        elif "timestamp" in df.columns:
            self.timestamps = pd.to_datetime(df["timestamp"]).values
        else:
            self.timestamps = np.arange(len(df))

        price_col = f"{self.base_period}_close"
        if price_col in df.columns:
            self.prices = df[price_col].values.astype(float)
        elif "close" in df.columns:
            self.prices = df["close"].values.astype(float)
        else:
            self.prices = np.zeros(len(df))

        print(f"âœ… æ—¶é—´æˆ³: {len(self.timestamps)} ä¸ª, ä»·æ ¼åŸºå‡†: {price_col}")

    def _process_period(self, df: pd.DataFrame, period: str) -> None:
        """å¤„ç†å•ä¸ªå‘¨æœŸçš„æ‰€æœ‰ç‰¹å¾"""

        # 1ï¸âƒ£ Market State
        states = calc_market_state_label(df, period)
        self.states_list.append(states.reshape(-1, 1))
        self.states_names.append(f"{period}_market_state")  # ğŸ”§ ç®€åŒ–å‘½åï¼šç§»é™¤å†—ä½™çš„ now_ å’Œ _win100
        self.states_types.append("classification")
        self.num_classes.append(2)
        analyze_state_distribution(states, period)

        # 2ï¸âƒ£ Momentum
        momentum, mom_col = calc_momentum_feature(
            df, period, self.cfg, self.roll_mode, self.base_period, self.period_multipliers
        )
        self.states_list.append(momentum.reshape(-1, 1))
        self.states_names.append(mom_col)
        self.states_types.append("regression")
        self.num_classes.append(1)

        # 3ï¸âƒ£ Band Width
        band_width, bw_col = calc_band_width_feature(
            df, period, self.cfg, self.roll_mode, self.base_period, self.period_multipliers
        )
        self.states_list.append(band_width.reshape(-1, 1))
        self.states_names.append(bw_col)
        self.states_types.append("regression")
        self.num_classes.append(1)

        # 4ï¸âƒ£ Volume
        volume, vol_col = calc_volume_feature(
            df, period, self.cfg, self.roll_mode, self.base_period, self.period_multipliers
        )
        self.states_list.append(volume.reshape(-1, 1))
        self.states_names.append(vol_col)
        self.states_types.append("regression")
        self.num_classes.append(1)

        # 5ï¸âƒ£ ATR
        self._process_atr(df, period)

        # 6ï¸âƒ£ RV
        self._process_rv(df, period)

    def _process_atr(self, df: pd.DataFrame, period: str) -> None:
        """å¤„ç†ATRç‰¹å¾"""
        atr_pct_col = f"{period}_atr_pct"
        atr_col = f"{period}_atr"
        close_col = f"{period}_close"

        if atr_pct_col in df.columns:
            base = pd.to_numeric(df[atr_pct_col], errors="coerce").fillna(0.0).values.astype(float)
        elif atr_col in df.columns and close_col in df.columns:
            atr = pd.to_numeric(df[atr_col], errors="coerce").fillna(0.0).values.astype(float)
            close = pd.to_numeric(df[close_col], errors="coerce").fillna(1e-8).values.astype(float)
            with np.errstate(divide="ignore", invalid="ignore"):
                base = atr / np.where(close == 0.0, np.nan, close)
            base = np.nan_to_num(base, nan=0.0, posinf=0.0, neginf=0.0)
        else:
            return

        atr_cfg = self.cfg.get("atr", {})
        fast_base = int(atr_cfg.get("fast_base", 25))
        slow_base = int(atr_cfg.get("slow_base", 100))
        fuse_w_fast = float(atr_cfg.get("fuse_w_fast", 0.6))
        fuse_w_slow = float(atr_cfg.get("fuse_w_slow", 0.4))
        epsilon = float(atr_cfg.get("shrink_epsilon", 0.03))

        x = np.log1p(np.maximum(base, 0.0))
        finite_x = x[np.isfinite(x)]
        if finite_x.size > 0:
            try:
                q_low, q_high = np.percentile(finite_x, [2.0, 98.0])
                if q_high > q_low:
                    x = np.clip(x, q_low, q_high)
            except Exception:
                pass

        fast_window = int(fast_base * self.period_multipliers.get(period, 1))
        slow_window = int(slow_base * self.period_multipliers.get(period, 1))
        rank_fast = calc_percentile_rank(x, fast_window)
        rank_slow = calc_percentile_rank(x, slow_window)
        fused = fuse_w_fast * rank_fast + fuse_w_slow * rank_slow

        # å•è¾¹å¹‚æ ¡å‡†ï¼ˆç¡®ä¿ä¸Š5%æ¥è¿‘1ï¼‰
        calib_cfg = atr_cfg.get("calibration") or {}
        calib_p = float(calib_cfg.get("p", 0.95))
        calib_target = float(calib_cfg.get("target", 0.99))
        per_period_cfg = (calib_cfg.get("per_period") or {}).get(period) or {}
        fixed_gamma = per_period_cfg.get("fixed_gamma", calib_cfg.get("fixed_gamma"))
        fixed_quantile = per_period_cfg.get("fixed_quantile", calib_cfg.get("fixed_quantile"))

        if fixed_gamma is not None:
            gamma_val = float(fixed_gamma)
            out = _apply_fixed_power_calibration(fused, gamma_val, epsilon)
            print(f"   â„¹ï¸  {period}: atr_pct ä½¿ç”¨å›ºå®š gamma={gamma_val:.4f}")
        elif fixed_quantile is not None:
            q = float(fixed_quantile)
            q = float(np.clip(q, 1e-6, 1.0 - 1e-6))
            gamma_val = float(np.log(max(calib_target, 1e-6)) / np.log(q))
            out = _apply_fixed_power_calibration(fused, gamma_val, epsilon)
            print(f"   â„¹ï¸  {period}: atr_pct ä½¿ç”¨å›ºå®š quantile={q:.4f} è®¡ç®— gamma={gamma_val:.4f}")
        else:
            finite_mask = np.isfinite(fused)
            if finite_mask.any():
                q = float(np.quantile(fused[finite_mask], calib_p))
                q = float(np.clip(q, 1e-6, 1.0 - 1e-6))
                gamma_val = float(np.log(max(calib_target, 1e-6)) / np.log(q))
                out = _apply_fixed_power_calibration(fused, gamma_val, epsilon)
                print(f"   â„¹ï¸  {period}: atr_pct åŠ¨æ€ gamma={gamma_val:.4f} (quantile={q:.4f})")
            else:
                out = _calibrate_one_sided_power(fused, p=calib_p, target=calib_target, epsilon=epsilon)

        self.states_list.append(out.reshape(-1, 1))
        self.states_names.append(f"{period}_atr_pct")
        self.states_types.append("regression")
        self.num_classes.append(1)
        print(f"âœ… {period}: atr_pct")

    def _process_rv(self, df: pd.DataFrame, period: str) -> None:
        """å¤„ç†Realized Volatilityç‰¹å¾"""
        from tools.columns import find_columns_by_pattern

        rv_cols = find_columns_by_pattern(df, r"(?:rv(?:_?win)?\d+|rv\b)", period=period)

        if not rv_cols:
            return

        for rv_col in rv_cols:
            canonical_name = re.sub(rf"^({period})_rv(?:_?win)?\d+(?:_(?:fixed|roll))?$", r"\1_rv", str(rv_col))
            if canonical_name in self.states_names:
                continue

            rv_vals = pd.to_numeric(df[rv_col], errors="coerce").fillna(0.0).values.astype(float)
            self.states_list.append(rv_vals.reshape(-1, 1))
            self.states_names.append(canonical_name)
            self.states_types.append("regression")
            self.num_classes.append(1)
            print(f"âœ… {period}: {canonical_name}")
            break

    def _process_rsi_features(self, df: pd.DataFrame) -> None:
        """
        å¤„ç†RSIç‰¹å¾

        ğŸ”¥ é‡è¦ï¼šRSIè¶…ä¹°è¶…å–äº‹ä»¶å·²åœ¨Step3è®¡ç®—ï¼Œè¿™é‡Œç›´æ¥è¯»å–
           - Step3è¾“å‡º: rsi14, rsi_overbought, rsi_oversold, rsi_event
           - Step5ä»»åŠ¡: å½’ä¸€åŒ–RSIå€¼ï¼Œç›´æ¥è¯»å–äº‹ä»¶åˆ—
        """
        print("\nâœ… å¤„ç†RSIç‰¹å¾...")

        # ğŸ”¥ å¤„ç†æ‰€æœ‰å‘¨æœŸçš„ RSIï¼ˆåŒ…æ‹¬åŸºç¡€å‘¨æœŸï¼‰
        # åŸå› ï¼šè®­ç»ƒå’Œå®ç›˜éƒ½éœ€è¦å®Œæ•´çš„ RSI ç‰¹å¾é›†
        rsi_periods = self.periods

        for rsi_period in rsi_periods:
            rsi_col = _detect_rsi_column(df, rsi_period)
            base_rsi_col = _detect_rsi_column(df, self.base_period)
            rsi_vals = None

            # ğŸ”¥ æ»šåŠ¨æ¨¡å¼å…¼å®¹ï¼ˆå·²å¼ƒç”¨ï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰
            if self.roll_mode and rsi_period != self.base_period and base_rsi_col:
                win = int(self.period_multipliers.get(rsi_period, 1))
                base_rsi = pd.to_numeric(df[base_rsi_col], errors="coerce").fillna(50.0).values.astype(float)
                rsi_vals = self._sma(base_rsi, max(1, win))
            elif rsi_col:
                rsi_vals = pd.to_numeric(df[rsi_col], errors="coerce").fillna(50.0).values.astype(float)

            if rsi_vals is not None:
                # ğŸ”¥ 1. RSIå½’ä¸€åŒ–ï¼ˆ-1åˆ°1èŒƒå›´ï¼Œç”¨äºRLæ¨¡å‹è¾“å…¥ï¼‰
                # æ³¨æ„ï¼šRSIå·²åœ¨Step3æ”¹é€ ä¸º[-100, +100]èŒƒå›´ï¼Œ0ä¸ºä¸­æ€§ç‚¹
                # ğŸš€ SACä¼˜åŒ–ï¼šä½¿ç”¨å¯é…ç½®çš„ç¼©æ”¾ç³»æ•°ï¼ˆé»˜è®¤80ï¼‰ï¼Œæ”¾å¤§ä¿¡å·åˆ†è¾¨ç‡
                # åŸç†ï¼šå®é™…RSIå¾ˆå°‘è¶…è¿‡Â±80ï¼Œç”¨80ä½œä¸ºåˆ†æ¯å¯ä»¥è®©å¸¸ç”¨åŒºé—´[-60,+60]
                #      å……åˆ†åˆ©ç”¨[-1,1]ç©ºé—´ï¼Œæå‡SACçš„æ¢¯åº¦æ•æ„Ÿåº¦
                # æ•ˆæœï¼šRSI=+80 â†’ 1.0 (æ»¡æ ¼å¤šå¤´), RSI=+60 â†’ 0.75 (å¼ºå¤šå¤´)
                #      RSI=-80 â†’ -1.0 (æ»¡æ ¼ç©ºå¤´), RSI=-60 â†’ -0.75 (å¼ºç©ºå¤´)
                rsi_cfg = self.norm_config.get("rsi", {})
                divisor = float(rsi_cfg.get("normalization_divisor", 80.0))  # é»˜è®¤80

                rsi_norm = rsi_vals / divisor
                rsi_norm = np.clip(rsi_norm, -1.0, 1.0)  # æå€¼æˆªæ–­ï¼ˆæŠ—å™ªï¼‰

                self.states_list.append(rsi_norm.reshape(-1, 1))
                self.states_names.append(f"{rsi_period}_rsi")
                self.states_types.append("regression")
                self.num_classes.append(1)

                # ğŸ”¥ 2. ç›´æ¥è¯»å–Step3ç”Ÿæˆçš„äº‹ä»¶åˆ—ï¼ˆä¸å†é‡æ–°è®¡ç®—ï¼‰
                # ä¼˜å…ˆè¯»å–æ–°æ ¼å¼ rsi_event
                event_col = f"{rsi_period}_rsi_event"
                ob_col = f"{rsi_period}_rsi_overbought"
                os_col = f"{rsi_period}_rsi_oversold"

                has_event = event_col in df.columns
                has_ob_os = (ob_col in df.columns) and (os_col in df.columns)

                if has_event:
                    # æ–°æ ¼å¼ï¼šç›´æ¥è¯»å– rsi_event (-1/0/+1)
                    rsi_event = pd.to_numeric(df[event_col], errors="coerce").fillna(0.0).values.astype(float)
                    self.states_list.append(rsi_event.reshape(-1, 1))
                    self.states_names.append(f"{rsi_period}_rsi_event")
                    self.states_types.append("classification")
                    self.num_classes.append(3)  # -1, 0, +1
                    print(f"   â””â”€ {rsi_period}_rsi + rsi_event (ä»Step3è¯»å–)")

                if has_ob_os:
                    # æ—§æ ¼å¼å…¼å®¹ï¼šè¯»å– overbought/oversold (0/1)
                    overbought = pd.to_numeric(df[ob_col], errors="coerce").fillna(0.0).values.astype(float)
                    oversold = pd.to_numeric(df[os_col], errors="coerce").fillna(0.0).values.astype(float)
                    self.states_list.extend([overbought.reshape(-1, 1), oversold.reshape(-1, 1)])
                    self.states_names.extend([f"{rsi_period}_rsi_overbought", f"{rsi_period}_rsi_oversold"])
                    self.states_types.extend(["classification", "classification"])
                    self.num_classes.extend([2, 2])
                    if not has_event:  # åªåœ¨æ²¡æœ‰æ–°æ ¼å¼æ—¶æ‰“å°
                        print(f"   â””â”€ {rsi_period}_rsi + events (ä»Step3è¯»å–ï¼Œæ—§æ ¼å¼)")

                if not has_event and not has_ob_os:
                    # ğŸš¨ å…¼å®¹æ—§æ•°æ®ï¼šå¦‚æœStep3æœªç”Ÿæˆäº‹ä»¶åˆ—ï¼Œå›é€€åˆ°æœ¬åœ°è®¡ç®—
                    print(f"   âš ï¸  {rsi_period}: Step3æœªç”Ÿæˆäº‹ä»¶åˆ—ï¼Œå›é€€åˆ°æœ¬åœ°è®¡ç®—")

                    # ğŸ”¥ ä»é…ç½®è¯»å–é˜ˆå€¼ï¼ˆå…¼å®¹æ–°ç‰ˆ RSI: -100 to +100, é˜ˆå€¼ Â±40ï¼‰
                    rsi_cfg = self.cfg.get("rsi", {})
                    min_persist = int(rsi_cfg.get("min_persist", 2))
                    upper_threshold = float(rsi_cfg.get("upper_threshold", 40.0))  # æ–°ç‰ˆé»˜è®¤ 40
                    lower_threshold = float(rsi_cfg.get("lower_threshold", -40.0))  # æ–°ç‰ˆé»˜è®¤ -40

                    # è®¡ç®—æ–°æ ¼å¼
                    rsi_event = self._compute_rsi_event(rsi_vals, upper_threshold, lower_threshold, min_persist)
                    self.states_list.append(rsi_event.reshape(-1, 1))
                    self.states_names.append(f"{rsi_period}_rsi_event")
                    self.states_types.append("classification")
                    self.num_classes.append(3)

                    # è®¡ç®—æ—§æ ¼å¼
                    overbought, oversold = self._compute_rsi_signal(
                        rsi_vals, upper_threshold, lower_threshold, min_persist
                    )
                    self.states_list.extend([overbought.reshape(-1, 1), oversold.reshape(-1, 1)])
                    self.states_names.extend([f"{rsi_period}_rsi_overbought", f"{rsi_period}_rsi_oversold"])
                    self.states_types.extend(["classification", "classification"])
                    self.num_classes.extend([2, 2])

                    print(f"   â””â”€ {rsi_period}_rsi + events (æœ¬åœ°è®¡ç®—ï¼Œé˜ˆå€¼: {lower_threshold}/{upper_threshold})")

    def _sma(self, values: np.ndarray, window: int) -> np.ndarray:
        """ç®€æ˜“SMA"""
        if window <= 1:
            v = np.asarray(values, dtype=float)
            v[~np.isfinite(v)] = 0.0
            return v
        v = np.asarray(values, dtype=float)
        v[~np.isfinite(v)] = 0.0
        out = np.zeros_like(v, dtype=float)
        csum = np.cumsum(v)
        for i in range(len(v)):
            start = max(0, i - window + 1)
            total = csum[i] - (csum[start - 1] if start > 0 else 0.0)
            out[i] = total / (i - start + 1)
        out[~np.isfinite(out)] = 0.0
        return out

    def _compute_rsi_event(self, rsi_vals: np.ndarray, upper: float, lower: float, min_persist: int) -> np.ndarray:
        """
        ğŸ”¥ RSIäº‹ä»¶ï¼ˆå•åˆ—ä¸‰å€¼è¾“å‡ºï¼š-1/0/+1ï¼‰

        è¿”å›æ ¼å¼ï¼š
            +1 = è¶…ä¹°è§¦å‘ï¼ˆçœ‹ç©ºä¿¡å·ï¼Œåº”å‡å¤šä»“æˆ–å¼€ç©ºä»“ï¼‰
             0 = ä¸­æ€§ï¼ˆæœªè§¦å‘ä»»ä½•äº‹ä»¶ï¼‰
            -1 = è¶…å–è§¦å‘ï¼ˆçœ‹å¤šä¿¡å·ï¼Œåº”å‡ç©ºä»“æˆ–å¼€å¤šä»“ï¼‰

        ä¼˜åŠ¿ï¼š
            - å•åˆ—è¡¨ç¤ºï¼Œæ›´ç›´è§‚
            - -1/+1 å¯¹ç§°ï¼Œç¬¦åˆ"å¯¹ç«‹äº‹ä»¶"è¯­ä¹‰
            - é¿å…0å€¼è¢«è¯¯è®¤ä¸º"æ— ä¿¡å·"
        """
        rsi = np.asarray(rsi_vals, dtype=float)
        ob = (rsi >= upper).astype(int)
        os = (rsi <= lower).astype(int)

        def _persist(mask: np.ndarray) -> np.ndarray:
            """æŒç»­æ€§è¿‡æ»¤ï¼šå¿…é¡»è¿ç»­min_persistä¸ªå‘¨æœŸæ‰è§¦å‘"""
            if min_persist <= 1:
                return mask
            out = np.zeros_like(mask)
            run = 0
            for i, v in enumerate(mask):
                run = run + 1 if v else 0
                if run >= min_persist:
                    out[i] = 1
            return out

        ob_filtered = _persist(ob)
        os_filtered = _persist(os)

        # ğŸ”¥ åˆå¹¶ä¸ºå•åˆ—ä¸‰å€¼
        event = np.zeros_like(rsi, dtype=float)
        event[ob_filtered == 1] = 1.0  # è¶…ä¹° â†’ +1
        event[os_filtered == 1] = -1.0  # è¶…å– â†’ -1

        return event

    def _compute_rsi_signal(
        self, rsi_vals: np.ndarray, upper: float, lower: float, min_persist: int
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        RSIè¶…ä¹°/è¶…å–ä¿¡å·ï¼ˆæ—§æ ¼å¼ï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰

        è¿”å›æ ¼å¼ï¼š
            è¶…ä¹°åˆ—: 1=è¶…ä¹°è§¦å‘, 0=æœªè§¦å‘
            è¶…å–åˆ—: 1=è¶…å–è§¦å‘, 0=æœªè§¦å‘
        """
        rsi = np.asarray(rsi_vals, dtype=float)
        ob = (rsi >= upper).astype(int)
        os = (rsi <= lower).astype(int)

        def _persist(mask: np.ndarray) -> np.ndarray:
            """æŒç»­æ€§è¿‡æ»¤ï¼šå¿…é¡»è¿ç»­min_persistä¸ªå‘¨æœŸæ‰è§¦å‘"""
            if min_persist <= 1:
                return mask
            out = np.zeros_like(mask)
            run = 0
            for i, v in enumerate(mask):
                run = run + 1 if v else 0
                if run >= min_persist:
                    out[i] = 1
            return out

        return _persist(ob), _persist(os)

    def _process_time_encoding(self) -> None:
        """å¤„ç†æ—¶é—´ç¼–ç """
        print("\nâœ… å¤„ç†æ—¶é—´ç¼–ç ...")

        try:
            ts = pd.to_datetime(self.timestamps, utc=True)
            day_of_week = ts.dayofweek.values if hasattr(ts, "dayofweek") else np.array([0] * len(ts))
            hour_of_day = ts.hour.values if hasattr(ts, "hour") else np.array([0] * len(ts))

            day_theta = 2.0 * np.pi * (day_of_week.astype(float) % 7.0) / 7.0
            day_sin = np.sin(day_theta)
            day_cos = np.cos(day_theta)
            self.states_list.extend([day_sin.reshape(-1, 1), day_cos.reshape(-1, 1)])
            self.states_names.extend(["time_day_sin", "time_day_cos"])
            self.states_types.extend(["regression", "regression"])
            self.num_classes.extend([1, 1])

            hour_theta = 2.0 * np.pi * (hour_of_day.astype(float) % 24.0) / 24.0
            hour_sin = np.sin(hour_theta)
            hour_cos = np.cos(hour_theta)
            self.states_list.extend([hour_sin.reshape(-1, 1), hour_cos.reshape(-1, 1)])
            self.states_names.extend(["time_hour_sin", "time_hour_cos"])
            self.states_types.extend(["regression", "regression"])
            self.num_classes.extend([1, 1])

            print("   â””â”€ sin/cosç¼–ç å®Œæˆ")
        except Exception as e:
            print(f"âš ï¸ æ—¶é—´ç¼–ç å¤±è´¥: {e}")

    def _process_base_prices(self, df: pd.DataFrame) -> None:
        """å¤„ç†åŸºå‡†ä»·æ ¼"""
        print(f"\nâœ… å¤„ç†åŸºå‡†ä»·æ ¼ï¼ˆ{self.base_period}ï¼‰...")

        price_cols = [
            f"{self.base_period}_open",
            f"{self.base_period}_high",
            f"{self.base_period}_low",
            f"{self.base_period}_close",
        ]

        for price_col in price_cols:
            if price_col in df.columns:
                price_data = df[price_col].values.astype(float)
                self.states_list.append(price_data.reshape(-1, 1))
                self.states_names.append(price_col)
                self.states_types.append("regression")
                self.num_classes.append(1)
                print(f"   â””â”€ {price_col}")

    def _process_returns(self, df: pd.DataFrame) -> None:
        """
        å¤„ç†æ”¶ç›Šç‡ç‰¹å¾

        ğŸ”¥ å…³é”®æ”¹è¿›ï¼šåœ¨ç‰¹å¾ç”Ÿæˆé˜¶æ®µå°±å®Œæˆ winsorize+tanh æ²»ç†
        - é¿å…è®­ç»ƒ/å®ç›˜æµç¨‹ä¸ä¸€è‡´
        - ç¡®ä¿æ‰€æœ‰ä½¿ç”¨è¯¥ç‰¹å¾çš„åœ°æ–¹éƒ½è·å¾—æ²»ç†åçš„æ•°æ®
        """
        print(f"\nâœ… å¤„ç†æ”¶ç›Šç‡...")

        base_price_col = f"{self.base_period}_close"
        if base_price_col not in df.columns:
            return

        # 1. è®¡ç®—å¯¹æ•°æ”¶ç›Šç‡
        p = df[base_price_col].astype(float).values
        p_safe_prev = np.where(p[:-1] == 0.0, 1e-8, p[:-1])
        log_ret = np.zeros_like(p, dtype=float)
        if len(p) > 1:
            log_ret[1:] = np.log(p[1:] / p_safe_prev)

        # 2. åº”ç”¨æ”¶ç›Šç‡æ²»ç†ï¼ˆwinsorize + tanhï¼‰
        ret_cfg = self.cfg.get("return_feature", {})
        enable_governance = bool(ret_cfg.get("enable_governance", True))

        if enable_governance:
            log_ret = self._apply_return_governance(log_ret, ret_cfg)

        # 3. æ·»åŠ åˆ°ç»“æœ
        self.states_list.append(log_ret.reshape(-1, 1))
        self.states_names.append(f"ret_{self.base_period}_log")
        self.states_types.append("regression")
        self.num_classes.append(1)

        gov_status = "å·²æ²»ç†" if enable_governance else "åŸå§‹å€¼"
        print(f"   â””â”€ ret_{self.base_period}_log ({gov_status})")

    def _apply_return_governance(self, ret: np.ndarray, cfg: Dict) -> np.ndarray:
        """
        å¯¹æ”¶ç›Šç‡ç‰¹å¾åº”ç”¨æ²»ç†ï¼ˆwinsorize + tanhï¼‰

        æ²»ç†æµç¨‹ï¼š
        1. Winsorize: è£å‰ªæç«¯å€¼åˆ° [p_lo, p_hi] åˆ†ä½æ•°
        2. Tanh: å‹ç¼©åˆ° [-1, 1] èŒƒå›´ï¼Œé¿å…æç«¯å€¼å½±å“æ¨¡å‹

        Args:
            ret: åŸå§‹å¯¹æ•°æ”¶ç›Šç‡
            cfg: æ²»ç†é…ç½®

        Returns:
            æ²»ç†åçš„æ”¶ç›Šç‡
        """
        ret_arr = np.asarray(ret, dtype=float)
        finite_mask = np.isfinite(ret_arr)

        if not finite_mask.any():
            return ret_arr

        # è¯»å–é…ç½®
        p_lo = float(cfg.get("winsorize_p_lo", 0.1))  # 0.1%åˆ†ä½æ•°
        p_hi = float(cfg.get("winsorize_p_hi", 99.9))  # 99.9%åˆ†ä½æ•°
        tanh_scale_factor = float(cfg.get("tanh_scale_factor", 3.0))  # tanhç¼©æ”¾å› å­

        # 1ï¸âƒ£ Winsorize: è£å‰ªæç«¯å€¼
        lo_bound = float(np.percentile(ret_arr[finite_mask], p_lo))
        hi_bound = float(np.percentile(ret_arr[finite_mask], p_hi))
        ret_clipped = np.clip(ret_arr, lo_bound, hi_bound)

        # 2ï¸âƒ£ Tanhå‹ç¼©: è®¡ç®—ç¼©æ”¾å› å­
        std_ref = float(np.std(ret_clipped[finite_mask]))
        eps = 1e-12
        tanh_scale = tanh_scale_factor * max(std_ref, eps)

        # åº”ç”¨tanhå‹ç¼©
        ret_governed = np.tanh(ret_clipped / tanh_scale)

        # è¿˜åŸNaNä½ç½®
        ret_governed[~finite_mask] = 0.0

        # æ‰“å°æ²»ç†ç»Ÿè®¡
        try:
            print(f"      ğŸ§ª æ”¶ç›Šç‡æ²»ç†ç»Ÿè®¡:")
            print(f"         Winsorize: [{lo_bound:.6f}, {hi_bound:.6f}] (p=[{p_lo:.1f}%, {p_hi:.1f}%])")
            print(f"         Tanh scale: {tanh_scale:.6f} (factor={tanh_scale_factor})")
            print(f"         åŸå§‹èŒƒå›´: [{np.min(ret_arr[finite_mask]):.6f}, {np.max(ret_arr[finite_mask]):.6f}]")
            print(
                f"         æ²»ç†åèŒƒå›´: [{np.min(ret_governed[finite_mask]):.6f}, {np.max(ret_governed[finite_mask]):.6f}]"
            )
        except Exception:
            pass

        return ret_governed

    def _assemble_results(self) -> Dict[str, Any]:
        """ç»„è£…æœ€ç»ˆç»“æœ"""
        print("\n" + "=" * 70)
        print("ğŸ“¦ æ•°æ®æ‰“åŒ…")
        print("=" * 70)

        all_states = np.concatenate(self.states_list, axis=1)
        observations = all_states.copy()

        print(f"âœ… Stateså½¢çŠ¶: {all_states.shape}")
        print(f"âœ… Observationså½¢çŠ¶: {observations.shape}")
        print(f"   - åˆ†ç±»ç‰¹å¾: {sum(1 for t in self.states_types if t == 'classification')}")
        print(f"   - å›å½’ç‰¹å¾: {sum(1 for t in self.states_types if t == 'regression')}")

        return {
            "observations": observations.astype(np.float32),
            "observation_names": [str(n) for n in self.states_names],
            "states": all_states.astype(np.float32),
            "state_names": [str(n) for n in self.states_names],
            "state_types": [str(t) for t in self.states_types],
            "num_classes": np.array(self.num_classes, dtype=int),
            "timestamps": self.timestamps,
            "prices": self.prices,
            "periods": self.periods,
        }
