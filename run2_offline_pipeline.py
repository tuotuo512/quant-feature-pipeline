# 3) volume ç¼ºå¤±å¡« 0
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Run2: ç¦»çº¿æµæ°´çº¿ç»Ÿä¸€å…¥å£ï¼ˆStep2 â†’ Step5ï¼‰

å½“å‰è„šæœ¬ç›´æ¥è°ƒç”¨ `unified_feature_pipeline.generate_rl_features`
ä¸€æ¬¡æ€§å®Œæˆ Step2/Step3/Step4/Step5ï¼Œå¹¶ä¿æŒåŸæœ‰çš„ CLI ä½“éªŒã€‚
"""

from __future__ import annotations

import argparse
import os
import sys
from pathlib import Path
import pandas as pd

CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.abspath(os.path.join(CURRENT_DIR, ".."))
for path in (PROJECT_ROOT, CURRENT_DIR):
    if path not in sys.path:
        sys.path.insert(0, path)

from features_engineering.congfigs.config_loader import ConfigLoader
from tools.io_paths import IOManager
from unified_feature_pipeline import generate_rl_features, PipelineResult


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Run2: ç¦»çº¿æµæ°´çº¿ Step2â†’Step5ï¼ˆç»Ÿä¸€å…¥å£ï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python run2_offline_pipeline.py
  python run2_offline_pipeline.py --start 2024-01-01 --end 2024-12-31
  python run2_offline_pipeline.py --sample_ratio 0.001
        """,
    )
    parser.add_argument("--start", type=str, default=None, help="èµ·å§‹æ—¶é—´(å¯é€‰)ï¼Œä¾‹å¦‚ 2024-01-01 00:00:00")
    parser.add_argument("--end", type=str, default=None, help="ç»“æŸæ—¶é—´(å¯é€‰)")
    parser.add_argument("--sample_ratio", type=float, default=None, help="é‡‡æ ·æ¯”ä¾‹(0-1)ï¼Œç”¨äºå¿«é€ŸéªŒç®—")
    parser.add_argument("--output_dir", type=str, default=None, help="é‡å®šå‘ RL npz è¾“å‡ºç›®å½•")
    parser.add_argument("--verbose", action="store_true", help="æ‰“å°å®Œæ•´æµæ°´çº¿æ—¥å¿—ï¼ˆé»˜è®¤å·²å¼€å¯ï¼‰")
    parser.add_argument(
        "--legacy-output-format",
        dest="legacy_output_format",
        choices=["csv", "parquet", "both"],
        default=None,
        help="å…¼å®¹æ—§å‚æ•°ï¼Œå®é™…è¾“å‡ºä»ç”± main_config.yaml æ§åˆ¶",
    )
    return parser.parse_args()


def _export_merged_header_txt(merged_file: str, header_txt_path: str) -> None:
    """å¤ç”¨æ—§é€»è¾‘ï¼Œè¾“å‡º merged æ–‡ä»¶çš„åˆ—ä¿¡æ¯ä¸æ—¶é—´èŒƒå›´ã€‚"""
    lower = merged_file.lower()
    if lower.endswith(".parquet"):
        df = pd.read_parquet(merged_file)
    else:
        df = pd.read_csv(merged_file)

    if "timestamp" in df.columns:
        if pd.api.types.is_integer_dtype(df["timestamp"]):
            df["timestamp"] = pd.to_datetime(df["timestamp"], unit="ms", errors="coerce")
        else:
            df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce")
        ts = df["timestamp"]
    elif isinstance(df.index, pd.DatetimeIndex):
        ts = df.index
    else:
        first_col = df.iloc[:, 0]
        if pd.api.types.is_integer_dtype(first_col):
            df.iloc[:, 0] = pd.to_datetime(first_col, unit="ms", errors="coerce")
        else:
            df.iloc[:, 0] = pd.to_datetime(first_col, errors="coerce")
        ts = df.iloc[:, 0]

    cols = [c for c in df.columns if c.lower() not in ("timestamp", "time", "datetime")]
    out_lines = [
        "=" * 80,
        "ğŸ“Š Mergedç‰¹å¾æ–‡ä»¶å…ƒæ•°æ®æ‘˜è¦",
        "=" * 80,
        "",
        f"ğŸ“‚ æ–‡ä»¶è·¯å¾„: {merged_file}",
        "",
        "=" * 80,
        "â° æ—¶é—´èŒƒå›´",
        "=" * 80,
        f"èµ·å§‹æ—¶é—´: {ts.min()}",
        f"ç»“æŸæ—¶é—´: {ts.max()}",
        f"æ•°æ®è¡Œæ•°: {len(df):,}",
        "",
        "=" * 80,
        f"ğŸ“‹ ç‰¹å¾åˆ—è¡¨ (å…± {len(cols)} åˆ—)",
        "=" * 80,
    ]
    out_lines.extend(f"  â€¢ {c}" for c in cols)
    Path(header_txt_path).parent.mkdir(parents=True, exist_ok=True)
    Path(header_txt_path).write_text("\n".join(out_lines), encoding="utf-8")
    print(f"ğŸ“ å·²ç”Ÿæˆç‰¹å¾æ‘˜è¦: {Path(header_txt_path).name}")


def _print_config_summary(cfg: dict, io_mgr: IOManager) -> None:
    exchange = cfg.get("exchange", {}).get("name", "unknown")
    symbol = cfg.get("symbol", {}).get("trading_pair_std", "UNKNOWN")
    market_type = cfg.get("symbol", {}).get("market_type", "swap")
    tf_cfg = cfg.get("timeframes", {}) or {}
    base = tf_cfg.get("base_download", "1m")
    targets = tf_cfg.get("resample_targets", [])
    source_mode = cfg.get("rl_build", {}).get("source_mode", "fixed")

    print("ğŸ“‹ é…ç½®æ‘˜è¦:")
    print(f"   äº¤æ˜“æ‰€: {exchange.upper()}")
    print(f"   äº¤æ˜“å¯¹: {symbol} ({market_type.upper()})")
    print(f"   åŸºç¡€å‘¨æœŸ: {base}")
    print(f"   ç›®æ ‡å‘¨æœŸ: {', '.join(targets)}")
    print(f"   æ•°æ®æ¨¡å¼: {source_mode.upper()}")
    print(f"\nğŸ“‚ è·¯å¾„é…ç½®:")
    print(f"   ä¸‹è½½ç›®å½•: {io_mgr.downloads_dir}")
    print(f"   Kçº¿ç›®å½•: {io_mgr.kline_dir}")
    print(f"   æŒ‡æ ‡ç›®å½•: {io_mgr.indicators_dir}")
    print(f"   èåˆç›®å½•: {io_mgr.merged_dir}")
    print(f"   RLè¾“å‡ºç›®å½•: {io_mgr.rl_ready_dir}")


def _summarize_pipeline_result(res: PipelineResult) -> None:
    print("\n" + "=" * 80)
    print("âœ… Run2 ç¦»çº¿æµæ°´çº¿æ‰§è¡Œå®Œæˆï¼")
    print("=" * 80)
    print(f"ğŸ“¦ merged:   {res.merged_path}")
    print(f"ğŸ“¦ features: {res.features_path}")
    print(f"ğŸ“¦ labels:   {res.labels_path}")
    print(f"ğŸ“Š è®°å½•æ•°: {res.records}")

    header_txt = str(Path(res.merged_path).with_suffix("")) + "_header.txt"
    try:
        _export_merged_header_txt(res.merged_path, header_txt)
    except Exception as e:
        print(f"âš ï¸ ç”Ÿæˆ merged æ‘˜è¦å¤±è´¥: {e}")

    print("\nğŸ’¡ ä¸‹ä¸€æ­¥æ“ä½œ:")
    print("   1) ä½¿ç”¨ preflight/run_preflight_seed.py å¯¹æ¯”å®ç›˜ vs è®­ç»ƒç‰¹å¾")
    print("   2) ä½¿ç”¨ run3_featueres_unified.py æˆ–è®­ç»ƒè„šæœ¬ç»§ç»­ä¸‹æ¸¸æµç¨‹")


def main() -> int:
    args = parse_args()

    if args.legacy_output_format:
        print(f"â„¹ï¸ æç¤º: --legacy-output-format å·²åºŸå¼ƒï¼Œä»å°†ä½¿ç”¨ main_config.yaml ä¸­çš„ io.output_format")

    try:
        loader = ConfigLoader()
        main_cfg = loader.load_main_config()
    except Exception as e:
        print(f"âŒ åŠ è½½ main_config.yaml å¤±è´¥: {e}")
        return 1

    if not main_cfg:
        print("âŒ main_config.yaml ä¸ºç©ºæˆ–ä¸å­˜åœ¨")
        return 1

    io_mgr = IOManager(main_cfg)
    _print_config_summary(main_cfg, io_mgr)

    print("\n" + "=" * 80)
    print("ğŸ”„ å¼€å§‹æ‰§è¡Œç»Ÿä¸€æµæ°´çº¿")
    print("=" * 80)

    res = generate_rl_features(
        mode="offline",
        start=args.start,
        end=args.end,
        sample_ratio=args.sample_ratio,
        output_dir=args.output_dir,
        verbose=True,
    )

    _summarize_pipeline_result(res)
    return 0


if __name__ == "__main__":
    sys.exit(main())
