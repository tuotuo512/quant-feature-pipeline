"""
é…ç½®åŠ è½½å™¨ - ç»Ÿä¸€ç®¡ç†æ‰€æœ‰é…ç½®æ–‡ä»¶çš„è¯»å–å’ŒéªŒè¯
ç”¨é€”: ä¸ºæ•°æ®å¤„ç†æµæ°´çº¿æä¾›æ ‡å‡†åŒ–çš„é…ç½®æ¥å£
"""

import os
import re
import copy
import yaml
from pathlib import Path
from typing import Any, Dict, Optional
from datetime import datetime


class ConfigLoader:
    """é…ç½®åŠ è½½å™¨ - è´Ÿè´£è¯»å–å’ŒéªŒè¯YAMLé…ç½®"""

    def __init__(self, config_dir: Optional[str] = None):
        """
        åˆå§‹åŒ–é…ç½®åŠ è½½å™¨

        å‚æ•°:
            config_dir: é…ç½®æ–‡ä»¶ç›®å½•ï¼Œé»˜è®¤ä¸ºå½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
        """
        if config_dir is None:
            # å½“å‰æ–‡ä»¶ä½äº congfigs/ ç›®å½•ï¼Œé»˜è®¤ä½¿ç”¨è¯¥ç›®å½•
            current_file = Path(__file__).resolve()
            config_dir = current_file.parent

        self.config_dir = Path(config_dir)

        if not self.config_dir.exists():
            raise FileNotFoundError(f"é…ç½®ç›®å½•ä¸å­˜åœ¨: {self.config_dir}")

        print(f"é…ç½®ç›®å½•: {self.config_dir}")

    def load_yaml(self, filename: str) -> Dict[str, Any]:
        """
        åŠ è½½YAMLé…ç½®æ–‡ä»¶

        å‚æ•°:
            filename: é…ç½®æ–‡ä»¶å

        è¿”å›:
            é…ç½®å­—å…¸
        """
        file_path = self.config_dir / filename

        if not file_path.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

        with open(file_path, "r", encoding="utf-8") as f:
            config = yaml.safe_load(f)

        if config is None:
            config = {}

        print(f"[OK] å·²åŠ è½½é…ç½®æ–‡ä»¶: {filename}")
        return config

    # ================= æ–°å¢ï¼šä¸»é…ç½®ä¸å ä½ç¬¦æ’å€¼/çº§è”åˆå¹¶ =================
    def load_main_config(self) -> Dict[str, Any]:
        """åŠ è½½å¹¶è§£æ main_config.yamlï¼ˆå«å ä½ç¬¦å†…éƒ¨æ’å€¼ + è‡ªåŠ¨æ¨å¯¼ï¼‰ã€‚"""
        try:
            cfg = self.load_yaml("main_config.yaml")
        except FileNotFoundError:
            return {}

        # [HOT] è‡ªåŠ¨æ¨å¯¼ï¼šæ ¹æ® rl_build.source_mode æ¨å¯¼ timeframes.include_rolling
        rl_build = cfg.get("rl_build", {})
        source_mode = rl_build.get("source_mode", "fixed")

        if "timeframes" not in cfg:
            cfg["timeframes"] = {}

        # æ¨å¯¼é€»è¾‘ï¼šsliding â†’ include_rolling=trueï¼›fixed â†’ false
        cfg["timeframes"]["include_rolling"] = source_mode == "sliding"

        # [HOT] æå– market_type åˆ°é¡¶å±‚ï¼Œä¾¿äºå ä½ç¬¦å¼•ç”¨ {market_type}
        symbol_cfg = cfg.get("symbol", {})
        market_type = symbol_cfg.get("market_type", "swap")
        cfg["market_type"] = market_type.upper()  # è½¬å¤§å†™ç”¨äºæ–‡ä»¶å‘½åï¼ˆSWAP/SPOTï¼‰

        print(
            f"[INFER] æ¨å¯¼: rl_build.source_mode='{source_mode}' -> timeframes.include_rolling={cfg['timeframes']['include_rolling']}"
        )
        print(
            f"[INFER] æ¨å¯¼: symbol.market_type='{market_type}' -> market_type='{cfg['market_type']}' (ç”¨äºæ–‡ä»¶å‘½å)"
        )

        # å¤šè½®æ’å€¼ï¼Œè§£å†³ä¸»é…ç½®å†…éƒ¨ç›¸äº’å¼•ç”¨ï¼ˆå¦‚ io.downloads_dir å¼•ç”¨ io.base_dirï¼‰
        resolved = self._resolve_placeholders_multi_pass(cfg, cfg, max_passes=4)
        return resolved

    # ================= é…ç½®å¯¹é½æ ¡éªŒ =================
    def validate_live_alignment(self, live_cfg: Dict[str, Any]) -> None:
        """
        æ ¡éªŒ live_overrides.yaml ä¸ä¸»é…ç½®çš„ä¸€è‡´æ€§ã€‚
        è‹¥å‘ç°å…³é”®å­—æ®µä¸ä¸€è‡´ï¼Œç›´æ¥æŠ›å‡º ValueError é˜»æ–­è¿è¡Œã€‚
        """
        if not isinstance(live_cfg, dict):
            raise ValueError("live_overrides é…ç½®æ— æ•ˆï¼šåº”ä¸º dict")

        main_cfg = self.load_main_config()
        issues = []

        # 1. å‘¨æœŸå¥‘çº¦ï¼šbase_period ä¸ resample_targets
        main_timeframes = main_cfg.get("timeframes", {}) or {}
        main_resample = [str(p) for p in (main_timeframes.get("resample_targets") or [])]
        expected_base = main_resample[0] if main_resample else ""

        fc_cfg = live_cfg.get("features_contract") or {}
        live_base = str(fc_cfg.get("base_period") or "")
        live_periods = [str(p) for p in (fc_cfg.get("periods_in_use") or [])]

        if expected_base and live_base and live_base != expected_base:
            issues.append(
                f"features_contract.base_period åº”ä¸ main_config.timeframes.resample_targets[0] å¯¹é½ï¼š å½“å‰ live={live_base}, expected={expected_base}"
            )

        if main_resample:
            expected_periods = sorted(set(main_resample))
            current_periods = sorted(set(live_periods))
            if current_periods and current_periods != expected_periods:
                issues.append(
                    "features_contract.periods_in_use åº”ä¸ main_config.timeframes.resample_targets å®Œå…¨ä¸€è‡´ï¼š"
                    f" å½“å‰ live={current_periods}, expected={expected_periods}"
                )

        # 2. ç‰¹å¾æºè·¯å¾„ï¼šåº”æŒ‡å‘ main_config.io.rl_ready_dir ä¸‹çš„æ ‡å‡†å‘½åæ–‡ä»¶
        # ğŸ”¥ æ”¯æŒ {symbol} å ä½ç¬¦ï¼ˆä» live_overrides.yaml çš„ exchanges é…ç½®åŠ¨æ€è·å–ï¼‰
        io_cfg = main_cfg.get("io", {}) or {}
        rl_ready_dir = io_cfg.get("rl_ready_dir")
        
        # ğŸ”¥ ä¼˜å…ˆä» live_cfg.exchanges è·å– symbol
        symbol_std = self._resolve_symbol_from_exchanges(live_cfg)
        if not symbol_std:
            symbol_cfg = main_cfg.get("symbol", {}) or {}
            symbol_std = symbol_cfg.get("trading_pair_std")
        
        source_cfg = fc_cfg.get("source") or {}
        source_pattern = source_cfg.get("path_pattern")
        if rl_ready_dir and symbol_std and live_base and source_pattern:
            expected_path = os.path.join(rl_ready_dir, f"{symbol_std}_{live_base}_rl_features.npz")
            try:
                # ğŸ”¥ æ”¯æŒ {symbol} å’Œ {base_period} ä¸¤ä¸ªå ä½ç¬¦
                resolved_pattern = source_pattern.format(symbol=symbol_std, base_period=live_base)
            except KeyError:
                resolved_pattern = source_pattern
            if os.path.abspath(resolved_pattern) != os.path.abspath(expected_path):
                issues.append(
                    "features_contract.source.path_pattern åº”æŒ‡å‘ä¸»é…ç½® rl_ready_dir ä¸‹çš„æ ‡å‡†æ–‡ä»¶ï¼š"
                    f" å½“å‰è·¯å¾„={resolved_pattern}, æœŸæœ›={expected_path}"
                )

        # 3. microbatch / save_nï¼šé¢„æ£€ä¸æµæ°´çº¿åº”å…±ç”¨åŒä¸€çª—å£
        micro_cfg = (main_cfg.get("online") or {}).get("microbatch") or {}
        expected_micro_len = micro_cfg.get("length")
        preheat_cfg = live_cfg.get("preheat") or {}
        live_save_n = preheat_cfg.get("save_n")
        if expected_micro_len and live_save_n and int(expected_micro_len) != int(live_save_n):
            issues.append(
                f"live_overrides.preheat.save_n ({live_save_n}) åº”ä¸ main_config.online.microbatch.length ({expected_micro_len}) ä¸€è‡´"
            )

        if issues:
            msg = "live_overrides ä¸ä¸»é…ç½®å­˜åœ¨ä¸ä¸€è‡´:\n- " + "\n- ".join(issues)
            raise ValueError(msg)

    def _resolve_symbol_from_exchanges(self, live_cfg: Dict[str, Any]) -> Optional[str]:
        """
        ğŸ”¥ ä» live_overrides.yaml çš„ exchanges é…ç½®è¯»å–å¯ç”¨çš„äº¤æ˜“æ‰€çš„ symbol
        
        Returns:
            symbol_stdï¼ˆå¦‚ "BTC_USDT"ï¼‰ï¼Œå¦‚æœæœªé…ç½®åˆ™è¿”å› None
        """
        exchanges_cfg = live_cfg.get("exchanges", {}) or {}
        
        for ex_name in ["okx", "bitget"]:
            ex_cfg = exchanges_cfg.get(ex_name, {}) or {}
            if ex_cfg.get("enabled", False):
                symbol = ex_cfg.get("symbol")
                if symbol:
                    # è§£æï¼šä¾‹å¦‚ "BTC/USDT:USDT" â†’ "BTC_USDT"
                    return symbol.split(":")[0].replace("/", "_")
        
        return None

    def load_yaml_with_main(self, filename: str) -> Dict[str, Any]:
        """åŠ è½½ä»»æ„YAMLæ–‡ä»¶ï¼Œå¹¶ä½¿ç”¨ main_config è¿›è¡Œå ä½ç¬¦æ’å€¼ + åˆå¹¶ä¸»é…ç½®ã€‚"""
        cfg = self.load_yaml(filename)
        main_cfg = self.load_main_config()

        # å…ˆè§£æå ä½ç¬¦ï¼ˆStep YAMLä¸­çš„ {io.xxx} ç­‰å¼•ç”¨ï¼‰
        resolved_cfg = self._resolve_placeholders_multi_pass(cfg, main_cfg, max_passes=4)

        # å†å°†ä¸»é…ç½®çš„å…³é”®å­—æ®µåˆå¹¶åˆ° Step é…ç½®ï¼ˆç¡®ä¿ Step å¯ä»¥è®¿é—®å…¨å±€é…ç½®ï¼‰
        merged = self._deep_merge_dicts(main_cfg, resolved_cfg)

        return merged

    def load_step1_config(self) -> "Step1DataConfig":
        """åŠ è½½Step1æ•°æ®ä¸‹è½½é…ç½®"""
        config_dict = self.load_yaml_with_main("step1_data download.yaml")
        return Step1DataConfig(config_dict)

    def load_step2_config(self) -> Dict[str, Any]:
        """åŠ è½½Step2é…ç½®ï¼ˆè‡ªåŠ¨å¥—ç”¨ä¸»é…ç½®å ä½ç¬¦ï¼‰ã€‚"""
        return self.load_yaml_with_main("step2_resample.yaml")

    def load_step3_config(self) -> Dict[str, Any]:
        """åŠ è½½Step3é…ç½®ï¼›è‹¥ step3_indicators.yaml ç¼ºå¤±åˆ™å›é€€åˆ° base_indicators.yamlã€‚"""
        try:
            return self.load_yaml_with_main("step3_indicators.yaml")
        except FileNotFoundError:
            print("[WARN] step3_indicators.yaml æœªæ‰¾åˆ°ï¼Œå›é€€åˆ° base_indicators.yaml")
            return self.load_yaml_with_main("base_indicators.yaml")

    def load_step4_config(self) -> Dict[str, Any]:
        """åŠ è½½Step4é…ç½®ï¼ˆè‡ªåŠ¨å¥—ç”¨ä¸»é…ç½®å ä½ç¬¦ï¼‰ã€‚"""
        return self.load_yaml_with_main("step4_merge.yaml")

    def load_step5_config(self) -> Dict[str, Any]:
        """åŠ è½½Step5é…ç½®ï¼ˆè‡ªåŠ¨å¥—ç”¨ä¸»é…ç½®å ä½ç¬¦ï¼‰ã€‚"""
        return self.load_yaml_with_main("step5_mapping.yaml")

    # ================= è¾…åŠ©ï¼šå ä½ç¬¦è§£æ =================
    def _resolve_placeholders_multi_pass(
        self,
        cfg: Dict[str, Any],
        context: Dict[str, Any],
        max_passes: int = 3,
    ) -> Dict[str, Any]:
        """å¯¹ cfg è¿›è¡Œå¤šè½®å ä½ç¬¦è§£æï¼Œæ”¯æŒ {a.b.c} å½¢å¼ï¼›è‹¥æ•´å€¼å³å ä½ç¬¦ï¼Œåˆ™è¿”å›åŸç±»å‹å¯¹è±¡ã€‚"""
        result = copy.deepcopy(cfg)
        for _ in range(max_passes):
            before = yaml.dump(result, allow_unicode=True)
            result = self._resolve_placeholders_once(result, context)
            after = yaml.dump(result, allow_unicode=True)
            if before == after:
                break
            context = self._deep_merge_dicts(context, result)
        return result

    def _resolve_placeholders_once(self, obj: Any, context: Dict[str, Any]) -> Any:
        if isinstance(obj, dict):
            return {k: self._resolve_placeholders_once(v, context) for k, v in obj.items()}
        if isinstance(obj, list):
            return [self._resolve_placeholders_once(v, context) for v in obj]
        if isinstance(obj, str):
            return self._interpolate_string(obj, context)
        return obj

    def _interpolate_string(self, s: str, context: Dict[str, Any]) -> Any:
        s = s.strip()
        m = re.fullmatch(r"\{([\w\.]+)\}", s)
        if m:
            key = m.group(1)
            val = self._deep_get(context, key)
            return copy.deepcopy(val) if val is not None else s

        def repl(match: re.Match) -> str:
            key = match.group(1)
            val = self._deep_get(context, key)
            return "" if val is None else str(val)

        return re.sub(r"\{([\w\.]+)\}", repl, s)

    def _deep_get(self, data: Dict[str, Any], dotted_key: str) -> Any:
        cur = data
        for part in dotted_key.split("."):
            if isinstance(cur, dict) and part in cur:
                cur = cur[part]
            else:
                return None
        return cur

    def _deep_merge_dicts(self, base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
        if not isinstance(base, dict):
            return copy.deepcopy(override)
        result = copy.deepcopy(base)
        for k, v in (override or {}).items():
            if isinstance(v, dict) and isinstance(result.get(k), dict):
                result[k] = self._deep_merge_dicts(result[k], v)
            else:
                result[k] = copy.deepcopy(v)
        return result


class Step1DataConfig:
    """Step1æ•°æ®ä¸‹è½½é…ç½®çš„ç»“æ„åŒ–å¯¹è±¡"""

    def __init__(self, config_dict: Dict[str, Any]):
        """
        ä»é…ç½®å­—å…¸åˆå§‹åŒ–

        å‚æ•°:
            config_dict: ä»YAMLåŠ è½½çš„é…ç½®å­—å…¸
        """
        self.raw_config = config_dict

        self._parse_symbol_config()
        self._parse_time_range_config()
        self._parse_timeframes_config()
        self._parse_fetch_strategy_config()
        self._parse_network_config()
        self._parse_api_auth_config()
        self._parse_output_config()
        self._parse_logging_config()

    def _parse_symbol_config(self):
        exchange_cfg = self.raw_config.get("exchange", {})
        self.exchange_name = exchange_cfg.get("name", "binance")

        valid_exchanges = ["binance", "okx"]
        if self.exchange_name not in valid_exchanges:
            raise ValueError(f"æ— æ•ˆçš„äº¤æ˜“æ‰€: {self.exchange_name}ï¼Œå¯é€‰: binance | okx")

        symbol_cfg = self.raw_config.get("symbol", {})
        # ğŸ”¥ ä¼˜å…ˆä½¿ç”¨ trading_pair_exchangeï¼Œå…¼å®¹æ—§é…ç½®çš„ trading_pair
        self.trading_pair = symbol_cfg.get("trading_pair_exchange") or symbol_cfg.get("trading_pair", "ETH/USDT")
        self.trading_pair_std = symbol_cfg.get("trading_pair_std", self.trading_pair.replace("/", "_"))
        self.market_type = symbol_cfg.get("market_type", "swap")

        valid_market_types = ["spot", "swap"]
        if self.market_type not in valid_market_types:
            raise ValueError(f"æ— æ•ˆçš„å¸‚åœºç±»å‹: {self.market_type}ï¼Œå¯é€‰: spot(ç°è´§) | swap(æ°¸ç»­åˆçº¦)")

    def _parse_time_range_config(self):
        time_cfg = self.raw_config.get("time_range", {})
        self.time_mode = time_cfg.get("mode", "incremental")

        if self.time_mode == "incremental":
            incr_cfg = time_cfg.get("incremental", {})
            self.days_if_missing = incr_cfg.get("days_if_missing", 60)
            self.fill_missing = incr_cfg.get("fill_missing", True)
            self.initial_start = incr_cfg.get("initial_start", None)

        elif self.time_mode == "full":
            full_cfg = time_cfg.get("full", {})
            self.years_of_data = full_cfg.get("years_of_data", 2)

        elif self.time_mode == "days":
            days_cfg = time_cfg.get("days", {})
            self.recent_days = days_cfg.get("recent_days", 90)

        elif self.time_mode == "custom":
            custom_cfg = time_cfg.get("custom", {})
            self.start_date = custom_cfg.get("start_date")
            self.end_date = custom_cfg.get("end_date")

            if self.start_date:
                try:
                    datetime.strptime(self.start_date, "%Y-%m-%d")
                except ValueError:
                    raise ValueError(f"start_date æ ¼å¼é”™è¯¯: {self.start_date}ï¼Œåº”ä¸º YYYY-MM-DD")

            if self.end_date:
                try:
                    datetime.strptime(self.end_date, "%Y-%m-%d")
                except ValueError:
                    raise ValueError(f"end_date æ ¼å¼é”™è¯¯: {self.end_date}ï¼Œåº”ä¸º YYYY-MM-DD")

    def _parse_timeframes_config(self):
        tf_cfg = self.raw_config.get("timeframes", {})

        if "target" in tf_cfg:
            self.timeframe = tf_cfg["target"]
            self.timeframes = [self.timeframe]
        elif "multi" in tf_cfg:
            self.timeframes = tf_cfg["multi"]
            self.timeframe = self.timeframes[0] if self.timeframes else "5m"
        else:
            self.timeframe = "5m"
            self.timeframes = ["5m"]

    def _parse_fetch_strategy_config(self):
        fetch_cfg = self.raw_config.get("fetch_strategy", {})
        self.retry_count = fetch_cfg.get("retry_count", 5)
        self.batch_size = fetch_cfg.get("batch_size", 500)
        self.delay_ms = fetch_cfg.get("delay_ms", 500)
        self.timeout_ms = fetch_cfg.get("timeout_ms", 6000)

    def _parse_network_config(self):
        net_cfg = self.raw_config.get("network", {})
        self.auto_detect = net_cfg.get("auto_detect", True)
        self.use_proxy = net_cfg.get("use_proxy", True)
        self.proxy_url = net_cfg.get("proxy_url", "http://127.0.0.1:18081")

        conn_cfg = net_cfg.get("connectivity_check", {})
        self.connectivity_enabled = conn_cfg.get("enabled", True)
        self.test_google = conn_cfg.get("test_google", True)
        self.test_binance = conn_cfg.get("test_binance", True)
        self.strict_mode = conn_cfg.get("strict_mode", False)

    def _parse_api_auth_config(self):
        auth_cfg = self.raw_config.get("api_auth", {})
        self.use_env_auth = auth_cfg.get("use_env", True)
        self.require_auth = auth_cfg.get("require_auth", False)

    def _parse_output_config(self):
        out_cfg = self.raw_config.get("output", {})
        _home_default = os.path.join(os.path.expanduser("~"), "FinRL_bn", "data", "data_downloads")
        self.base_dir = out_cfg.get("base_dir", _home_default)
        self.filename_pattern = out_cfg.get("filename_pattern", "{symbol}_{timeframe}.csv")

        qc_cfg = out_cfg.get("quality_check", {})
        self.remove_duplicates = qc_cfg.get("remove_duplicates", True)
        self.fill_missing_values = qc_cfg.get("fill_missing_values", True)
        self.check_completeness = qc_cfg.get("check_completeness", True)
        self.add_time_features = qc_cfg.get("add_time_features", True)

    def _parse_logging_config(self):
        log_cfg = self.raw_config.get("logging", {})
        self.verbose = log_cfg.get("verbose", True)
        self.show_progress = log_cfg.get("show_progress", True)
        self.progress_interval = log_cfg.get("progress_interval", 5)
        self.save_log = log_cfg.get("save_log", False)
        self.log_file = log_cfg.get("log_file", "data_download.log")

    def get_output_filename(self, timeframe: Optional[str] = None) -> str:
        if timeframe is None:
            timeframe = self.timeframe

        pattern = self.filename_pattern
        if pattern.endswith("_.csv"):
            return pattern[:-5] + f"_{timeframe}.csv"

        try:
            return pattern.format(
                symbol=self.trading_pair.replace("/", "_"),
                timeframe=timeframe,
                start_date="",
                end_date="",
            )
        except (KeyError, ValueError):
            return f"{self.trading_pair.replace('/', '_')}_{self.market_type.upper()}_{timeframe}.csv"

    def get_output_path(self, timeframe: Optional[str] = None) -> str:
        filename = self.get_output_filename(timeframe)
        return os.path.join(self.base_dir, filename)

    def print_summary(self):
        print("\n" + "=" * 60)
        print("[CLIPBOARD] æ•°æ®ä¸‹è½½é…ç½®æ‘˜è¦")
        print("=" * 60)
        print(f"äº¤æ˜“æ‰€: {self.exchange_name}")
        print(f"äº¤æ˜“å¯¹: {self.trading_pair}")
        print(f"å¸‚åœºç±»å‹: {self.market_type}")
        print(f"æ—¶é—´å‘¨æœŸ: {', '.join(self.timeframes)}")
        print(f"æ—¶é—´æ¨¡å¼: {self.time_mode}")

        if self.time_mode == "incremental":
            print(f"  - æœ¬åœ°æ— æ–‡ä»¶æ—¶æŠ“å–å¤©æ•°: {self.days_if_missing}")
            print(f"  - è¡¥é½ç¼ºå¤±Kçº¿: {self.fill_missing}")
            if self.initial_start:
                print(f"  - åˆå§‹èµ·ç‚¹: {self.initial_start}")
        elif self.time_mode == "full":
            print(f"  - å†å²æ•°æ®å¹´æ•°: {self.years_of_data}")
        elif self.time_mode == "days":
            print(f"  - æœ€è¿‘å¤©æ•°: {self.recent_days}")
        elif self.time_mode == "custom":
            print(f"  - å¼€å§‹æ—¥æœŸ: {self.start_date}")
            print(f"  - ç»“æŸæ—¥æœŸ: {self.end_date}")

        print(f"\nç½‘ç»œé…ç½®:")
        print(f"  - è‡ªåŠ¨æ£€æµ‹: {self.auto_detect}")
        print(f"  - ä½¿ç”¨ä»£ç†: {self.use_proxy}")
        if self.use_proxy:
            print(f"  - ä»£ç†åœ°å€: {self.proxy_url}")

        print(f"\nè·å–ç­–ç•¥:")
        print(f"  - é‡è¯•æ¬¡æ•°: {self.retry_count}")
        print(f"  - æ‰¹æ¬¡å¤§å°: {self.batch_size}")
        print(f"  - å»¶è¿Ÿ(ms): {self.delay_ms}")
        print(f"  - è¶…æ—¶(ms): {self.timeout_ms}")

        print(f"\nè¾“å‡ºé…ç½®:")
        print(f"  - ä¿å­˜ç›®å½•: {self.base_dir}")
        print(f"  - æ–‡ä»¶å: {self.get_output_filename()}")
        print(f"  - å»é‡: {self.remove_duplicates}")
        print(f"  - è¡¥ç¼º: {self.fill_missing_values}")
        print("=" * 60 + "\n")


if __name__ == "__main__":
    print("æµ‹è¯•é…ç½®åŠ è½½å™¨...")

    try:
        loader = ConfigLoader()
        config = loader.load_step1_config()
        config.print_summary()

        print("\n[OK] é…ç½®åŠ è½½æµ‹è¯•æˆåŠŸï¼")

    except Exception as e:
        print(f"\n[ERROR] é…ç½®åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
