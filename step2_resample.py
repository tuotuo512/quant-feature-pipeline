#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Step2: Kçº¿é‡é‡‡æ ·å™¨ï¼ˆå®Œå…¨é…ç½®é©±åŠ¨ç‰ˆï¼‰

âœ¨ ç‰¹æ€§ï¼š
  - å®Œå…¨ç”± main_config.yaml + step2_resample.yaml é©±åŠ¨
  - è‡ªåŠ¨å¤„ç† fixed/sliding æ¨¡å¼
  - æ”¯æŒæ—¶é—´èŒƒå›´è¿‡æ»¤
  - æ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼

ğŸ“‹ ç”¨æ³•ï¼š
  python step2_resample.py
  python step2_resample.py --start 2024-01-01 --end 2024-12-31

ğŸ”§ é…ç½®ï¼š
  - å…¨å±€é…ç½®: main_config.yaml
  - é‡é‡‡æ ·ç­–ç•¥: step2_resample.yaml
"""

from __future__ import annotations

import os
import sys
import argparse
from pathlib import Path

try:
    import pandas as pd
except ImportError:
    print("âŒ å¯¼å…¥ pandas å¤±è´¥ï¼Œè¯·è¿è¡Œ: pip install pandas")
    sys.exit(1)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
_PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
if _PROJECT_ROOT not in sys.path:
    sys.path.insert(0, _PROJECT_ROOT)

try:
    from features_engineering.congfigs.config_loader import ConfigLoader
except Exception as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)

# å·¥å…·é›†ï¼ˆå¢é‡/è¯»å†™/æ—¶é—´ï¼‰
from features_engineering.tools.io_paths import (
    read_df_auto,
    get_last_timestamp,
    print_latest_timestamp_from_df,
)
from features_engineering.tools.incremental import (
    safe_concat_dedup,
)
from features_engineering.tools.time_index import (
    timeframe_to_minutes,
)


def parse_args() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="Step2: Kçº¿é‡é‡‡æ ·å™¨ï¼ˆå®Œå…¨é…ç½®é©±åŠ¨ï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # ä½¿ç”¨é»˜è®¤é…ç½®
  python step2_resample.py

  # æŒ‡å®šæ—¶é—´èŒƒå›´
  python step2_resample.py --start 2024-01-01 --end 2024-12-31

  # è¦†ç›–è¾“å‡ºæ ¼å¼
  python step2_resample.py --output_format parquet
        """,
    )
    parser.add_argument("--start", type=str, default=None, help="èµ·å§‹æ—¶é—´(å¯é€‰)ï¼Œå¦‚ 2024-01-01")
    parser.add_argument("--end", type=str, default=None, help="ç»“æŸæ—¶é—´(å¯é€‰)ï¼Œå¦‚ 2024-12-31")
    parser.add_argument(
        "--output_format",
        type=str,
        default=None,
        choices=["csv", "parquet", "both"],
        help="è¦†ç›–è¾“å‡ºæ ¼å¼ï¼ˆé»˜è®¤ä» main_config.yaml è¯»å–ï¼‰",
    )
    return parser.parse_args()


def detect_base_interval(df: pd.DataFrame) -> str:
    """æ£€æµ‹åŸºç¡€æ•°æ®çš„æ—¶é—´é—´éš”"""
    if len(df) < 2:
        return "1m"  # é»˜è®¤å‡è®¾1åˆ†é’Ÿ

    # è®¡ç®—å‰å‡ ä¸ªæ—¶é—´é—´éš”
    time_diffs = df.index[1:6] - df.index[0:5]
    avg_diff = time_diffs.mean()

    if abs(avg_diff.total_seconds() - 60) < 30:  # 1åˆ†é’Ÿ Â±30ç§’
        return "1m"
    elif abs(avg_diff.total_seconds() - 300) < 60:  # 5åˆ†é’Ÿ Â±1åˆ†é’Ÿ
        return "5m"
    elif abs(avg_diff.total_seconds() - 900) < 120:  # 15åˆ†é’Ÿ Â±2åˆ†é’Ÿ
        return "15m"
    else:
        # é»˜è®¤è¿”å›1åˆ†é’Ÿï¼Œä½†ç»™å‡ºè­¦å‘Š
        print(f"âš ï¸ æ— æ³•å‡†ç¡®æ£€æµ‹åŸºç¡€é—´éš”ï¼Œå¹³å‡é—´éš”: {avg_diff}ï¼Œå‡è®¾ä¸º1m")
        return "1m"


def read_base_csv(
    input_file: str, start: str | None = None, end: str | None = None
) -> tuple[pd.DataFrame, str]:
    """è¯»å–åŸºç¡€CSVï¼Œè§£ææ—¶é—´ç´¢å¼•ï¼Œè‡ªåŠ¨æ£€æµ‹é—´éš”ï¼Œå¹¶æŒ‰éœ€åˆ‡ç‰‡ã€‚"""
    if not os.path.exists(input_file):
        raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")

    # å°è¯•å¤šç§è¯»å–æ–¹å¼ï¼Œå…¼å®¹ index=timestamp æˆ–åˆ—å« timestamp
    try:
        df = pd.read_csv(input_file, parse_dates=[0], index_col=0)
        if df.index.name is None:
            df.index.name = "timestamp"
    except Exception:
        df = pd.read_csv(input_file)
        ts_col = None
        for cand in ["timestamp", "time", "datetime", "ts"]:
            if cand in df.columns:
                ts_col = cand
                break
        if ts_col is None:
            raise ValueError("CSV ä¸­æœªæ‰¾åˆ°æ—¶é—´åˆ—ï¼ˆtimestamp/time/datetime/tsï¼‰")
        # æ™ºèƒ½è§£æï¼šæ•´æ•°ç”¨æ¯«ç§’ï¼Œå­—ç¬¦ä¸²è‡ªåŠ¨æ¨æ–­
        if pd.api.types.is_integer_dtype(df[ts_col]):
            df[ts_col] = pd.to_datetime(df[ts_col], unit="ms", errors="coerce")
        else:
            df[ts_col] = pd.to_datetime(df[ts_col], errors="coerce")
        df = df.set_index(ts_col)
        df.index.name = "timestamp"

    # åªä¿ç•™æ ‡å‡†åˆ—
    keep_cols = [c for c in ["open", "high", "low", "close", "volume"] if c in df.columns]
    df = df[keep_cols]

    # æ’åº/å»é‡
    df = df[~df.index.duplicated(keep="last")].sort_index()

    # åˆ‡ç‰‡ï¼ˆstart/endé€šå¸¸æ˜¯å­—ç¬¦ä¸²ï¼Œä¸éœ€è¦æŒ‡å®šunitï¼‰
    if start:
        df = df[df.index >= pd.to_datetime(start)]
    if end:
        df = df[df.index <= pd.to_datetime(end)]

    if df.empty:
        raise ValueError("ç­›é€‰åçš„æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ—¶é—´èŒƒå›´æˆ–è¾“å…¥æ–‡ä»¶å†…å®¹")

    # æ£€æµ‹åŸºç¡€é—´éš”
    base_interval = detect_base_interval(df)

    return df, base_interval


def timeframe_to_rule(tf: str) -> str:
    """
    å‘¨æœŸå­—ç¬¦ä¸²è½¬ pandas resample è§„åˆ™ï¼ˆæ™ºèƒ½è§£æï¼Œæ”¯æŒä»»æ„å‘¨æœŸï¼‰

    æ”¯æŒæ ¼å¼:
    - åˆ†é’Ÿ: 1m, 3m, 5m, 10m, 15m, 30m, 45m ç­‰
    - å°æ—¶: 1h, 2h, 4h, 6h, 8h, 12h ç­‰
    - å¤©: 1d, 2d, 3d ç­‰
    - å‘¨: 1w, 2w ç­‰

    ç¤ºä¾‹:
        "5m" -> "5min"
        "2h" -> "2h"
        "1d" -> "1d"
    """
    tf = tf.strip().lower()

    # è§£ææ•°å­—å’Œå•ä½
    if not tf:
        raise ValueError("å‘¨æœŸå­—ç¬¦ä¸²ä¸èƒ½ä¸ºç©º")

    # æå–æ•°å­—éƒ¨åˆ†
    num_str = ""
    unit = ""
    for char in tf:
        if char.isdigit():
            num_str += char
        else:
            unit += char

    if not num_str or not unit:
        raise ValueError(f"æ— æ•ˆçš„å‘¨æœŸæ ¼å¼: {tf}ï¼Œåº”ä¸ºæ•°å­—+å•ä½ï¼Œå¦‚ '5m', '2h', '1d'")

    try:
        num = int(num_str)
    except ValueError:
        raise ValueError(f"æ— æ•ˆçš„å‘¨æœŸæ•°å­—: {num_str}")

    if num <= 0:
        raise ValueError(f"å‘¨æœŸæ•°å­—å¿…é¡»å¤§äº0: {num}")

    # æ˜ å°„å•ä½åˆ° pandas è§„åˆ™
    unit_mapping = {
        "m": "min",  # åˆ†é’Ÿ
        "min": "min",
        "h": "h",  # å°æ—¶
        "hour": "h",
        "d": "d",  # å¤©
        "day": "d",
        "w": "w",  # å‘¨
        "week": "w",
    }

    if unit not in unit_mapping:
        raise ValueError(f"ä¸æ”¯æŒçš„æ—¶é—´å•ä½: {unit}ï¼Œæ”¯æŒçš„å•ä½: {', '.join(unit_mapping.keys())}")

    pandas_unit = unit_mapping[unit]
    return f"{num}{pandas_unit}"


def resample_ohlcv(df_base: pd.DataFrame, tf: str, base_interval: str = "1m") -> pd.DataFrame:
    """åŸºç¡€å‘¨æœŸ â†’ æŒ‡å®šå‘¨æœŸçš„æ ‡å‡†OHLCVé‡é‡‡æ ·ã€‚æ”¯æŒ1m/5mç­‰åŸºç¡€æ•°æ®ã€‚"""
    # å¦‚æœç›®æ ‡å‘¨æœŸä¸åŸºç¡€å‘¨æœŸç›¸åŒï¼Œç›´æ¥è¿”å›å‰¯æœ¬
    if tf == base_interval:
        print(f"  ç›®æ ‡å‘¨æœŸä¸åŸºç¡€å‘¨æœŸç›¸åŒ ({tf})ï¼Œç›´æ¥å¤åˆ¶æ•°æ®")
        df = df_base.copy()
        df.index.name = "timestamp"
        return df

    rule = timeframe_to_rule(tf)
    agg = {
        "open": "first",
        "high": "max",
        "low": "min",
        "close": "last",
        "volume": "sum",
    }
    # TODO: ğŸ”¥ æœªæ¥æ•°æ®æ³„éœ²é£é™© - éœ€è¦é‡æ–°ç”Ÿæˆè®­ç»ƒæ•°æ®å¹¶é‡æ–°è®­ç»ƒæ¨¡å‹
    # closed='right': æ—¶é—´æˆ³Tçš„baråŒ…å« (T-period, T]ï¼ŒåŒ…å«Tæ—¶åˆ»çš„æ•°æ®ï¼ˆæœªæ¥æ•°æ®ï¼‰
    # æ­£ç¡®é…ç½®åº”è¯¥æ˜¯ closed='left': [T-period, T)ï¼Œä½†éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹
    df = df_base.resample(rule, label="right", closed="right").agg(agg)
    # ä¸¢å¼ƒä¸å®Œæ•´bar
    df = df.dropna(subset=["open", "high", "low", "close"]).copy()
    df.index.name = "timestamp"
    return df


def _tf_to_minutes(tf: str) -> int:
    """
    å°†å‘¨æœŸå­—ç¬¦ä¸²è½¬æ¢ä¸ºåˆ†é’Ÿæ•°ï¼ˆæ™ºèƒ½è§£æï¼‰

    ç¤ºä¾‹:
        "5m" -> 5
        "2h" -> 120
        "1d" -> 1440
        "1w" -> 10080
    """
    tf = tf.strip().lower()

    # æå–æ•°å­—å’Œå•ä½
    num_str = ""
    unit = ""
    for char in tf:
        if char.isdigit():
            num_str += char
        else:
            unit += char

    if not num_str or not unit:
        raise ValueError(f"æ— æ•ˆçš„å‘¨æœŸæ ¼å¼: {tf}")

    try:
        num = int(num_str)
    except ValueError:
        raise ValueError(f"æ— æ•ˆçš„å‘¨æœŸæ•°å­—: {num_str}")

    # å•ä½è½¬æ¢ä¸ºåˆ†é’Ÿæ•°
    unit_to_minutes = {
        "m": 1,  # åˆ†é’Ÿ
        "min": 1,
        "h": 60,  # å°æ—¶
        "hour": 60,
        "d": 1440,  # å¤© (24 * 60)
        "day": 1440,
        "w": 10080,  # å‘¨ (7 * 24 * 60)
        "week": 10080,
    }

    if unit not in unit_to_minutes:
        raise ValueError(f"ä¸æ”¯æŒçš„æ—¶é—´å•ä½: {unit}")

    return num * unit_to_minutes[unit]


def _interval_to_minutes(interval: str) -> int:
    return _tf_to_minutes(interval)


def rolling_preview_ohlcv(df_base: pd.DataFrame, tf: str, base_interval: str = "1m") -> pd.DataFrame:
    """
    ç”Ÿæˆä»¥åŸºç¡€æ­¥é•¿æ»šåŠ¨çš„é¢„è§ˆKçº¿ï¼ˆç”¨äºæœªæ”¶ç›˜rollingï¼‰ã€‚
    ä¾‹å¦‚ï¼šbase=5m, tf=15m â†’ çª—å£=3ï¼Œæ¯æ ¹5mæ›´æ–°ä¸€æ¬¡ï¼š
    open=çª—å£é¦–open, high=max, low=min, close=çª—å£æœ«close, volume=sumã€‚
    """
    tf_min = _tf_to_minutes(tf)
    base_min = _interval_to_minutes(base_interval)
    window = max(1, tf_min // base_min)
    if window <= 1:
        # ä¸åŸºç¡€ä¸€è‡´ï¼Œç›´æ¥å¤åˆ¶
        out = df_base.copy()
        out.index.name = "timestamp"
        return out

    # ä½¿ç”¨æ»šåŠ¨çª—å£èšåˆ
    o = df_base["open"].rolling(window, min_periods=window).apply(lambda x: x[0], raw=True)
    h = df_base["high"].rolling(window, min_periods=window).max()
    l = df_base["low"].rolling(window, min_periods=window).min()
    c = df_base["close"].rolling(window, min_periods=window).apply(lambda x: x[-1], raw=True)
    v = df_base["volume"].rolling(window, min_periods=window).sum()
    df = pd.DataFrame({"open": o, "high": h, "low": l, "close": c, "volume": v}, index=df_base.index)
    df = df.dropna(subset=["open", "high", "low", "close"]).copy()
    df.index.name = "timestamp"
    return df


def save_output(df: pd.DataFrame, kline_dir: str, symbol: str, tf: str, fmt: str, rolling: bool = False):
    """ä¿å­˜Kçº¿æ•°æ®ï¼ˆæ ¹ç›®å½•ï¼Œä¸åˆ›å»ºæŒ‰å‘¨æœŸå­ç›®å½•ï¼›æ–‡ä»¶å {symbol}_{tf}.parquet/csvï¼‰"""
    output_dir = Path(kline_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    fname = f"{symbol}_{tf}"

    if fmt in ("csv", "both"):
        csv_path = output_dir / f"{fname}.csv"
        df.reset_index().to_csv(csv_path, index=False)
        print(f"   âœ“ CSV: {csv_path.name}")

    if fmt in ("parquet", "both"):
        parquet_path = output_dir / f"{fname}.parquet"
        try:
            df.to_parquet(parquet_path, index=True)
            print(f"   âœ“ Parquet: {parquet_path.name}")
        except Exception as e:
            print(f"   âš ï¸ Parquet å†™å…¥å¤±è´¥: {e}")


def _find_existing_kline_path(kline_dir: str, symbol: str, tf: str, rolling: bool) -> Path | None:
    """æŸ¥æ‰¾å·²å­˜åœ¨çš„Kçº¿æ–‡ä»¶ï¼ˆä¼˜å…ˆæ ¹ç›®å½•ï¼›å…¼å®¹æ—§è·¯å¾„ kline/<tf>/... ä¸ _rollï¼‰ã€‚"""
    base_root = Path(kline_dir)
    name_new = f"{symbol}_{tf}"
    # 1) æ ¹ç›®å½•
    for ext in (".parquet", ".csv"):
        p = base_root / f"{name_new}{ext}"
        if p.exists():
            return p
    # 2) å…¼å®¹æ—§è·¯å¾„ï¼šå­ç›®å½• <tf>
    base_old = Path(kline_dir) / tf
    for ext in (".parquet", ".csv"):
        p = base_old / f"{name_new}{ext}"
        if p.exists():
            return p
    # 3) å…¼å®¹æ—§å _roll
    name_old = f"{symbol}_{tf}_roll"
    for ext in (".parquet", ".csv"):
        p = base_old / f"{name_old}{ext}"
        if p.exists():
            return p
    return None


def _compute_incremental_start_for_step2(
    kline_dir: str, symbol: str, targets: list[str], include_rolling: bool
) -> tuple[pd.Timestamp | None, bool]:
    """è¿”å›(æœ€æ—©å›æº¯èµ·ç‚¹, æ˜¯å¦æ£€æµ‹åˆ°å¯å¢é‡)ã€‚è‹¥ä¸å­˜åœ¨å†å²æ–‡ä»¶åˆ™è¿”å›(None, False)ã€‚"""
    last_starts: list[pd.Timestamp] = []
    detected = False
    for tf in targets:
        p = _find_existing_kline_path(kline_dir, symbol, tf, rolling=False)
        if p is None:
            continue
        detected = True
        last_ts = get_last_timestamp(str(p))
        if last_ts is None:
            continue
        warm_minutes = timeframe_to_minutes(tf)
        warm_start = pd.to_datetime(last_ts) - pd.Timedelta(minutes=warm_minutes)
        last_starts.append(warm_start)
        # rolling ä¹Ÿä¸€å¹¶è€ƒè™‘ï¼ˆè‹¥å­˜åœ¨ï¼‰
        if include_rolling:
            pr = _find_existing_kline_path(kline_dir, symbol, tf, rolling=True)
            if pr is not None:
                last_ts_r = get_last_timestamp(str(pr))
                if last_ts_r is not None:
                    warm_start_r = pd.to_datetime(last_ts_r) - pd.Timedelta(minutes=warm_minutes)
                    last_starts.append(warm_start_r)
    if not last_starts:
        return (None, detected)
    return (min(last_starts), True)


def execute_step2(
    cfg: dict,
    start: str | None = None,
    end: str | None = None,
    output_format: str | None = None,
    *,
    verbose: bool = True,
) -> dict:
    """æ‰§è¡Œ Step2 é‡é‡‡æ ·é€»è¾‘ï¼Œä¾›è„šæœ¬ä¸ç»Ÿä¸€æµæ°´çº¿å¤ç”¨ã€‚"""
    if not cfg:
        raise ValueError("é…ç½®ä¸èƒ½ä¸ºç©º")

    log = print if verbose else (lambda *args, **kwargs: None)

    log("ğŸš€ Step2 Kçº¿é‡é‡‡æ ·å¯åŠ¨ï¼ˆå®Œå…¨é…ç½®é©±åŠ¨ï¼‰\n")

    # ========== 1. æå–é…ç½®å‚æ•°ï¼ˆé›¶ç¡¬ç¼–ç ï¼‰==========
    symbol = cfg.get("symbol", {}).get("trading_pair_std", "ETH_USDT")
    market_type = cfg.get("symbol", {}).get("market_type", "swap")

    timeframes_cfg = cfg.get("timeframes", {})
    base_download = timeframes_cfg.get("base_download", "1m")
    timeframes = timeframes_cfg.get("resample_targets", ["3m", "15m", "30m", "2h"])
    include_rolling = timeframes_cfg.get("include_rolling", False)

    variant_val = timeframes_cfg.get("variant", None)
    if variant_val is None:
        variant_val = cfg.get("timeframes.variant", "")
    variant = str(variant_val or "").strip().lower()
    if variant not in ("fixed", "roll"):
        variant = "fixed"
    source_mode = cfg.get("rl_build", {}).get("source_mode", "fixed")

    io_cfg = cfg.get("io", {})
    base_dir = io_cfg.get("base_dir") or os.path.join(os.path.expanduser("~"), "FinRL_bn", "data")
    downloads_dir = io_cfg.get("downloads_dir") or f"{base_dir}/rl_live/data_downloads"
    kline_dir = io_cfg.get("kline_dir") or f"{base_dir}/rl_live/kline"

    output_fmt = output_format or io_cfg.get("output_format", "csv")
    io_overwrite = bool(io_cfg.get("overwrite", False))

    incr_start, detected_any = _compute_incremental_start_for_step2(
        kline_dir, symbol, timeframes, include_rolling
    )
    incremental_mode = (not io_overwrite) and (incr_start is not None)
    effective_start = start
    if effective_start is None and incremental_mode:
        effective_start = str(incr_start)

    input_filename = f"{symbol}_{market_type.upper()}_{base_download}.csv"
    input_file = os.path.join(downloads_dir, input_filename)

    # ========== 2. æ‰“å°é…ç½®æ‘˜è¦ ==========
    log("ğŸ“‹ é…ç½®æ‘˜è¦:")
    log(f"   äº¤æ˜“å¯¹: {symbol} ({market_type.upper()})")
    log(f"   åŸºç¡€å‘¨æœŸ: {base_download}")
    log(f"   ç›®æ ‡å‘¨æœŸ: {', '.join(timeframes)}")
    log(f"   æ•°æ®æ¨¡å¼: {source_mode.upper()} ({'æ»‘çª—æ»šåŠ¨' if source_mode == 'sliding' else 'å›ºå®šKçº¿'})")
    log(f"   è¾“å‡ºæ ¼å¼: {output_fmt.upper()}")
    if variant in ("fixed", "roll"):
        log(f"   è¾“å‡ºå˜ä½“: {variant.upper()}")
    log(f"\nğŸ“‚ è·¯å¾„é…ç½®:")
    log(f"   è¾“å…¥æ–‡ä»¶: {input_filename}")
    log(f"   è¾“å‡ºç›®å½•: {kline_dir}")
    if effective_start or end:
        log(f"\nâ° æ—¶é—´èŒƒå›´: {effective_start or '-âˆ'} ~ {end or '+âˆ'}")

    # ========== 3. è¯»å–è¾“å…¥æ•°æ® ==========
    if not os.path.exists(input_file):
        raise FileNotFoundError(
            f"æœªæ‰¾åˆ°è¾“å…¥æ–‡ä»¶: {input_file}\nè¯·å…ˆè¿è¡Œ Step1 ä¸‹è½½æ•°æ®: python run1_step1_data.py"
        )

    df_base, base_interval = read_base_csv(input_file, start=effective_start, end=end)
    log(f"\nâœ… è¯»å–å®Œæˆ: {len(df_base):,} è¡Œ")
    log(f"   æ—¶é—´èŒƒå›´: {df_base.index.min()} ~ {df_base.index.max()}")
    log(f"   åŸºç¡€é—´éš”: {base_interval}")

    # ========== 4. æ‰§è¡Œé‡é‡‡æ · ==========
    log("\n" + "=" * 80)
    log("ğŸ”„ å¼€å§‹é‡é‡‡æ ·")
    log("=" * 80)

    produce_fixed = variant == "fixed"
    produce_roll = variant == "roll"

    for tf in timeframes:
        log(f"\nğŸ“ å‘¨æœŸ: {tf}")

        try:
            if produce_fixed:
                tf_df = resample_ohlcv(df_base, tf, base_interval)
                log(f"   âœ“ Fixed: {len(tf_df):,} è¡Œ ({tf_df.index.min()} ~ {tf_df.index.max()})")
                if incremental_mode:
                    p_exist = _find_existing_kline_path(kline_dir, symbol, tf, rolling=False)
                    if p_exist is not None:
                        try:
                            old_df = read_df_auto(str(p_exist))
                            if "timestamp" in old_df.columns:
                                if pd.api.types.is_integer_dtype(old_df["timestamp"]):
                                    old_df["timestamp"] = pd.to_datetime(
                                        old_df["timestamp"], unit="ms", errors="coerce"
                                    )
                                else:
                                    old_df["timestamp"] = pd.to_datetime(old_df["timestamp"], errors="coerce")
                                old_df = old_df.set_index("timestamp")
                            old_df.index.name = "timestamp"
                        except Exception:
                            old_df = None
                        tf_df = safe_concat_dedup(old_df, tf_df)
                        log(f"   ğŸ” åˆå¹¶å†å²: {len(tf_df):,} è¡Œ")
                save_output(tf_df, kline_dir, symbol, tf, output_fmt, rolling=False)

            if produce_roll:
                tf_roll = rolling_preview_ohlcv(df_base, tf, base_interval)
                log(f"   âœ“ Rolling: {len(tf_roll):,} è¡Œ")
                if incremental_mode:
                    pr_exist = _find_existing_kline_path(kline_dir, symbol, tf, rolling=True)
                    if pr_exist is not None:
                        try:
                            old_r = read_df_auto(str(pr_exist))
                            if "timestamp" in old_r.columns:
                                old_r["timestamp"] = pd.to_datetime(old_r["timestamp"], errors="coerce")
                                old_r = old_r.set_index("timestamp")
                            old_r.index.name = "timestamp"
                        except Exception:
                            old_r = None
                        tf_roll = safe_concat_dedup(old_r, tf_roll)
                        log(f"   ğŸ” åˆå¹¶å†å²(roll): {len(tf_roll):,} è¡Œ")
                save_output(tf_roll, kline_dir, symbol, tf, output_fmt, rolling=True)

            log(f"   âœ… å‘¨æœŸ {tf} å®Œæˆ")

        except Exception as e:
            import traceback

            traceback.print_exc()
            raise RuntimeError(f"Step2 å‘¨æœŸ {tf} å¤„ç†å¤±è´¥: {e}") from e

    # ========== 5. è¾“å‡ºç»“æœæ‘˜è¦ ==========
    log("\n" + "=" * 80)
    log("âœ… Step2 Kçº¿é‡é‡‡æ ·å®Œæˆï¼")
    log("=" * 80)
    log(f"\nğŸ“‚ è¾“å‡ºç›®å½•: {kline_dir}")
    log(f"â±ï¸  å¤„ç†å‘¨æœŸ: {', '.join(timeframes)}")
    log(f"ğŸ”§ æ•°æ®æ¨¡å¼: {source_mode.upper()}")

    print_latest_timestamp_from_df(df_base)

    log(f"\nğŸ’¡ ä¸‹ä¸€æ­¥æ“ä½œ:")
    log(f"   è¿è¡Œ Step3 ç”ŸæˆæŒ‡æ ‡:")
    log(f"   python step3_generate_indicators.py")

    return {
        "symbol": symbol,
        "market_type": market_type,
        "base_download": base_download,
        "base_interval": base_interval,
        "timeframes": timeframes,
        "kline_dir": kline_dir,
        "downloads_dir": downloads_dir,
        "source_mode": source_mode,
        "incremental_mode": incremental_mode,
        "include_rolling": include_rolling,
        "start": df_base.index.min(),
        "end": df_base.index.max(),
        "detected_history": detected_any,
        "output_format": output_fmt,
    }


def main():
    """ä¸»æµç¨‹ï¼šå®Œå…¨é…ç½®é©±åŠ¨çš„Kçº¿é‡é‡‡æ ·"""
    args = parse_args()

    try:
        loader = ConfigLoader()
        cfg = loader.load_step2_config()
        if not cfg:
            print("âŒ æœªæ‰¾åˆ°æˆ–æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶")
            return 1
    except Exception as e:
        print(f"âŒ åŠ è½½é…ç½®å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
        return 1

    try:
        execute_step2(
            cfg,
            start=args.start,
            end=args.end,
            output_format=args.output_format,
            verbose=True,
        )
        return 0
    except Exception as e:
        print(f"âŒ Step2 æ‰§è¡Œå¤±è´¥: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())
